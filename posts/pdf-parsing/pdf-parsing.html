<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nicolas Brosse">
<meta name="dcterms.date" content="2025-02-18">
<meta name="description" content="An exploration of current PDF parsing capabilities for Large Language Model (LLM) input.">

<title>PDF Parsing for LLM Input – Nicolas’ Notebook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-313591559204ad6a7884cc02194e8f50.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Nicolas’ Notebook</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nbrosse"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/nicolas-brosse-984685a0/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">PDF Parsing for LLM Input</h1>
                  <div>
        <div class="description">
          An exploration of current PDF parsing capabilities for Large Language Model (LLM) input.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">LLM</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Nicolas Brosse </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 18, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-detailed-presentation" id="toc-sec-detailed-presentation" class="nav-link active" data-scroll-target="#sec-detailed-presentation">Detailed Presentations of PDF Parsing Libraries: Docling, Marker-pdf, MinerU</a>
  <ul class="collapse">
  <li><a href="#sec-docling" id="toc-sec-docling" class="nav-link" data-scroll-target="#sec-docling">Docling: A Modular PDF Processing Pipeline</a></li>
  <li><a href="#sec-marker-pdf" id="toc-sec-marker-pdf" class="nav-link" data-scroll-target="#sec-marker-pdf">Marker-PDF: Accurate PDF Conversion</a></li>
  <li><a href="#sec-mineru" id="toc-sec-mineru" class="nav-link" data-scroll-target="#sec-mineru">MinerU: Multi-Module Document Parsing</a></li>
  </ul></li>
  <li><a href="#sec-comparing-libraries" id="toc-sec-comparing-libraries" class="nav-link" data-scroll-target="#sec-comparing-libraries">Comparing PDF Parsing Libraries</a>
  <ul class="collapse">
  <li><a href="#pdf-sample-dataset" id="toc-pdf-sample-dataset" class="nav-link" data-scroll-target="#pdf-sample-dataset">PDF Sample Dataset</a></li>
  <li><a href="#qualitative-results" id="toc-qualitative-results" class="nav-link" data-scroll-target="#qualitative-results">Qualitative Results</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This blog post explores the current landscape of PDF parsing for use as input to Large Language Models (LLMs). Extracting meaningful information from PDFs can be challenging due to their complex structure. This article examines several approaches, their strengths, and limitations, with a focus on their suitability for LLM integration (markdown output).</p>
<p>We begin with a detailed presentation of some open-source PDF parsing libraries: Docling, Marker-PDF, and MinerU in <a href="#sec-detailed-presentation" class="quarto-xref">Section&nbsp;1</a>. In particular, we provide a comprehensive overview of the Docling pipeline, a modular and open-source PDF processing pipeline designed to transform PDFs into a structured representation (the <code>DoclingDocument</code>) in <a href="#sec-docling" class="quarto-xref">Section&nbsp;1.1</a>. We also discuss Marker-PDF and MinerU in <a href="#sec-marker-pdf" class="quarto-xref">Section&nbsp;1.2</a> and <a href="#sec-mineru" class="quarto-xref">Section&nbsp;1.3</a>. The objective is to gain an understanding of how modern PDF parsing libraries function, in particular the role of deep learning models in PDF parsing and extraction, focusing on layout analysis, table structure recognition, and Optical Character Recognition (OCR).</p>
<p>Following this, we compare and evaluate various PDF parsing libraries and tools in <a href="#sec-comparing-libraries" class="quarto-xref">Section&nbsp;2</a>, including open-source libraries (Docling, Marker, MinerU, PyMuPDF) and closed-source solutions (LlamaParse, Gemini). We provide a detailed comparison based on a qualitative analysis using a diverse set of test PDFs (slides, reports, scanned documents, and documents with complex tables). The results of this analysis are available through an interactive demo that visualizes the differences between PDF input and Markdown output for each parsing solution.</p>
<section id="sec-detailed-presentation" class="level1">
<h1>Detailed Presentations of PDF Parsing Libraries: Docling, Marker-pdf, MinerU</h1>
<section id="sec-docling" class="level2">
<h2 class="anchored" data-anchor-id="sec-docling">Docling: A Modular PDF Processing Pipeline</h2>
<p><strong>Overview</strong></p>
<p>Docling is a modular and extensible pipeline designed to ingest various document formats, primarily PDFs (but also DOCX, HTML, etc.), and transform them into a unified, structured representation: the <code>DoclingDocument</code>. The core aim is to create a standardized representation suitable for downstream tasks, such as feeding data into an LLM. Docling is in active development and is completely open-source. It provides a comprehensive technical documentation <span class="citation" data-cites="auer2024doclingtechnicalreport">(<a href="#ref-auer2024doclingtechnicalreport" role="doc-biblioref">Auer et al. 2024</a>)</span>, <span class="citation" data-cites="livathinos2025doclingefficientopensourcetoolkit">(<a href="#ref-livathinos2025doclingefficientopensourcetoolkit" role="doc-biblioref">Livathinos et al. 2025</a>)</span>.</p>
<div id="fig-docling-pipeline" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Docling's default processing pipeline.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-docling-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/docling-pipeline.png" class="img-fluid figure-img" alt="Docling's default processing pipeline.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-docling-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Sketch of Docling’s default processing pipeline. Source: <span class="citation" data-cites="auer2024doclingtechnicalreport">(<a href="#ref-auer2024doclingtechnicalreport" role="doc-biblioref">Auer et al. 2024</a>)</span>
</figcaption>
</figure>
</div>
<p>The Docling pipeline, as shown in <a href="#fig-docling-pipeline" class="quarto-xref">Figure&nbsp;1</a>, consists of the following stages:</p>
<ul>
<li>PDF Backend (for raw PDF document processing)</li>
<li>AI Models (Layout Analysis, Table Structure Recognition, OCR)</li>
<li>Assembly and Post-processing</li>
</ul>
<p><strong>PDF Backend</strong></p>
<p>The PDF backend is responsible for:</p>
<ol type="a">
<li>Retrieving all text content and their geometric coordinates on each page.</li>
<li>Rendering the visual representation of each page as it appears in a PDF viewer.</li>
</ol>
<p>These capabilities are encapsulated in Docling’s PDF backend interface. Docling provides multiple backend choices, including a custom-built PDF parser based on the low-level qpdf library. This parser is open-sourced as a separate package, <a href="https://github.com/DS4SD/docling-parse"><code>docling-parse</code></a>, and powers Docling’s default PDF backend. <a href="#fig-docling-parse" class="quarto-xref">Figure&nbsp;2</a> illustrates the parsing process.</p>
<div id="fig-docling-parse" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-docling-parse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/2305.14962v1.pdf_page=0.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Original PDF page</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/2305.14962v1.pdf_page=0.v2.sanitized.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Parsed PDF page</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-docling-parse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Illustration of docling parse from <a href="https://github.com/DS4SD/docling-parse?tab=readme-ov-file">source</a>.
</figcaption>
</figure>
</div>
<p>The <code>docling-parse</code> package provides a Python interface to extract text content, images, and annotations from PDFs. It also supports rendering PDF pages as images. The extracted content is serialized to JSON <a href="#lst-json-docling-parse" class="quarto-xref">Listing&nbsp;1</a>, which can be further processed by downstream components.</p>
<div id="lst-json-docling-parse" class="json listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-json-docling-parse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;1: Example of docling-parse JSON output
</figcaption>
<div aria-describedby="lst-json-docling-parse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="lst-json-docling-parse"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="lst-json-docling-parse-1"><a href="#lst-json-docling-parse-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="er">'annotations'</span><span class="fu">:</span> <span class="ot">[</span><span class="fu">{</span><span class="er">'/A'</span><span class="fu">:</span> <span class="fu">{</span><span class="er">'/IsMap'</span><span class="fu">:</span> <span class="er">False</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-2"><a href="#lst-json-docling-parse-2" aria-hidden="true" tabindex="-1"></a>    <span class="er">'/S'</span><span class="fu">:</span> <span class="er">'/URI'</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-3"><a href="#lst-json-docling-parse-3" aria-hidden="true" tabindex="-1"></a>    <span class="er">'/URI'</span><span class="fu">:</span> <span class="er">'https://www.deloitte.com/global/en/Industries/financial-services/perspectives/pushing-through-undercurrents.html'</span><span class="fu">},</span></span>
<span id="lst-json-docling-parse-4"><a href="#lst-json-docling-parse-4" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/BS'</span><span class="fu">:</span> <span class="fu">{</span><span class="er">'/S'</span><span class="fu">:</span> <span class="er">'/S'</span><span class="fu">,</span> <span class="er">'/Type'</span><span class="fu">:</span> <span class="er">'/Border'</span><span class="fu">,</span> <span class="er">'/W'</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">},</span></span>
<span id="lst-json-docling-parse-5"><a href="#lst-json-docling-parse-5" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Border'</span><span class="fu">:</span> <span class="ot">[</span><span class="dv">0</span><span class="ot">,</span> <span class="dv">0</span><span class="ot">,</span> <span class="dv">0</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-6"><a href="#lst-json-docling-parse-6" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/H'</span><span class="fu">:</span> <span class="er">'/N'</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-7"><a href="#lst-json-docling-parse-7" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Rect'</span><span class="fu">:</span> <span class="ot">[</span><span class="fl">474.409</span><span class="ot">,</span> <span class="fl">580.322</span><span class="ot">,</span> <span class="fl">512.947</span><span class="ot">,</span> <span class="fl">569.083</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-8"><a href="#lst-json-docling-parse-8" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Subtype'</span><span class="fu">:</span> <span class="er">'/Link'</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-9"><a href="#lst-json-docling-parse-9" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Type'</span><span class="fu">:</span> <span class="er">'/Annot'</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-10"><a href="#lst-json-docling-parse-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span><span class="er">'/A'</span><span class="fu">:</span> <span class="fu">{</span><span class="er">'/IsMap'</span><span class="fu">:</span> <span class="er">False</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-11"><a href="#lst-json-docling-parse-11" aria-hidden="true" tabindex="-1"></a>    <span class="er">'/S'</span><span class="fu">:</span> <span class="er">'/URI'</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-12"><a href="#lst-json-docling-parse-12" aria-hidden="true" tabindex="-1"></a>    <span class="er">'/URI'</span><span class="fu">:</span> <span class="er">'https://www.deloitte.com/global/en/Industries/financial-services/perspectives/pushing-through-undercurrents.html'</span><span class="fu">},</span></span>
<span id="lst-json-docling-parse-13"><a href="#lst-json-docling-parse-13" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/BS'</span><span class="fu">:</span> <span class="fu">{</span><span class="er">'/S'</span><span class="fu">:</span> <span class="er">'/S'</span><span class="fu">,</span> <span class="er">'/Type'</span><span class="fu">:</span> <span class="er">'/Border'</span><span class="fu">,</span> <span class="er">'/W'</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">},</span></span>
<span id="lst-json-docling-parse-14"><a href="#lst-json-docling-parse-14" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Border'</span><span class="fu">:</span> <span class="ot">[</span><span class="dv">0</span><span class="ot">,</span> <span class="dv">0</span><span class="ot">,</span> <span class="dv">0</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-15"><a href="#lst-json-docling-parse-15" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/H'</span><span class="fu">:</span> <span class="er">'/N'</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-16"><a href="#lst-json-docling-parse-16" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Rect'</span><span class="fu">:</span> <span class="ot">[</span><span class="fl">67.9417</span><span class="ot">,</span> <span class="fl">568.322</span><span class="ot">,</span> <span class="fl">286.919</span><span class="ot">,</span> <span class="fl">557.22</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-17"><a href="#lst-json-docling-parse-17" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Subtype'</span><span class="fu">:</span> <span class="er">'/Link'</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-18"><a href="#lst-json-docling-parse-18" aria-hidden="true" tabindex="-1"></a>   <span class="er">'/Type'</span><span class="fu">:</span> <span class="er">'/Annot'</span><span class="fu">}</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-docling-parse-19"><a href="#lst-json-docling-parse-19" aria-hidden="true" tabindex="-1"></a> <span class="er">'original'</span><span class="fu">:</span> <span class="fu">{</span><span class="er">'cells'</span><span class="fu">:</span> <span class="fu">{</span><span class="er">'data'</span><span class="fu">:</span> <span class="ot">[[</span><span class="fl">36.142</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-20"><a href="#lst-json-docling-parse-20" aria-hidden="true" tabindex="-1"></a>     <span class="fl">711.041</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-21"><a href="#lst-json-docling-parse-21" aria-hidden="true" tabindex="-1"></a>     <span class="fl">54.862</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-22"><a href="#lst-json-docling-parse-22" aria-hidden="true" tabindex="-1"></a>     <span class="fl">739.753</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-23"><a href="#lst-json-docling-parse-23" aria-hidden="true" tabindex="-1"></a>     <span class="fl">36.142</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-24"><a href="#lst-json-docling-parse-24" aria-hidden="true" tabindex="-1"></a>     <span class="fl">711.041</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-25"><a href="#lst-json-docling-parse-25" aria-hidden="true" tabindex="-1"></a>     <span class="fl">54.862</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-26"><a href="#lst-json-docling-parse-26" aria-hidden="true" tabindex="-1"></a>     <span class="fl">711.041</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-27"><a href="#lst-json-docling-parse-27" aria-hidden="true" tabindex="-1"></a>     <span class="fl">54.862</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-28"><a href="#lst-json-docling-parse-28" aria-hidden="true" tabindex="-1"></a>     <span class="fl">739.753</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-29"><a href="#lst-json-docling-parse-29" aria-hidden="true" tabindex="-1"></a>     <span class="fl">36.142</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-30"><a href="#lst-json-docling-parse-30" aria-hidden="true" tabindex="-1"></a>     <span class="fl">739.753</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-31"><a href="#lst-json-docling-parse-31" aria-hidden="true" tabindex="-1"></a>     <span class="er">'P'</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-32"><a href="#lst-json-docling-parse-32" aria-hidden="true" tabindex="-1"></a>     <span class="dv">-1</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-33"><a href="#lst-json-docling-parse-33" aria-hidden="true" tabindex="-1"></a>     <span class="fl">8.32</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-34"><a href="#lst-json-docling-parse-34" aria-hidden="true" tabindex="-1"></a>     <span class="er">'/WinAnsiEncoding'</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-35"><a href="#lst-json-docling-parse-35" aria-hidden="true" tabindex="-1"></a>     <span class="er">'WINANSI'</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-36"><a href="#lst-json-docling-parse-36" aria-hidden="true" tabindex="-1"></a>     <span class="er">'/TT0'</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-37"><a href="#lst-json-docling-parse-37" aria-hidden="true" tabindex="-1"></a>     <span class="er">'/FSUTKX+OpenSans-Light'</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-38"><a href="#lst-json-docling-parse-38" aria-hidden="true" tabindex="-1"></a>     <span class="er">False</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-39"><a href="#lst-json-docling-parse-39" aria-hidden="true" tabindex="-1"></a>     <span class="er">True</span><span class="ot">],</span></span>
<span id="lst-json-docling-parse-40"><a href="#lst-json-docling-parse-40" aria-hidden="true" tabindex="-1"></a>    <span class="ot">[</span><span class="fl">54.542</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-41"><a href="#lst-json-docling-parse-41" aria-hidden="true" tabindex="-1"></a>     <span class="fl">711.041</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-42"><a href="#lst-json-docling-parse-42" aria-hidden="true" tabindex="-1"></a>     <span class="fl">73.422</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-43"><a href="#lst-json-docling-parse-43" aria-hidden="true" tabindex="-1"></a>     <span class="fl">739.753</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-44"><a href="#lst-json-docling-parse-44" aria-hidden="true" tabindex="-1"></a>     <span class="fl">54.542</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-45"><a href="#lst-json-docling-parse-45" aria-hidden="true" tabindex="-1"></a>     <span class="fl">711.041</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-46"><a href="#lst-json-docling-parse-46" aria-hidden="true" tabindex="-1"></a>     <span class="fl">73.422</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-47"><a href="#lst-json-docling-parse-47" aria-hidden="true" tabindex="-1"></a>     <span class="fl">711.041</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-48"><a href="#lst-json-docling-parse-48" aria-hidden="true" tabindex="-1"></a>     <span class="fl">73.422</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-49"><a href="#lst-json-docling-parse-49" aria-hidden="true" tabindex="-1"></a>     <span class="fl">739.753</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-50"><a href="#lst-json-docling-parse-50" aria-hidden="true" tabindex="-1"></a>     <span class="fl">54.542</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-51"><a href="#lst-json-docling-parse-51" aria-hidden="true" tabindex="-1"></a>     <span class="fl">739.753</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-52"><a href="#lst-json-docling-parse-52" aria-hidden="true" tabindex="-1"></a>     <span class="er">'u'</span><span class="ot">,</span></span>
<span id="lst-json-docling-parse-53"><a href="#lst-json-docling-parse-53" aria-hidden="true" tabindex="-1"></a>     <span class="dv">-1</span><span class="ot">,</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<p><strong>AI Models</strong></p>
<p>Docling integrates several AI models for layout analysis and table structure recognition (TableFormer <span class="citation" data-cites="nassar2022tableformertablestructureunderstanding">(<a href="#ref-nassar2022tableformertablestructureunderstanding" role="doc-biblioref">Nassar et al. 2022</a>)</span>). Pre-trained weights (hosted on Hugging Face) and a separate package for inference code (<code>docling-ibm-models</code>) are available.</p>
<p><strong>Layout Analysis Model</strong></p>
<p>This model detects and classifies various elements on a page image by predicting bounding boxes. The architecture is based on RT-DETR and retrained on DocLayNet <span class="citation" data-cites="Pfitzmann_2022">(<a href="#ref-Pfitzmann_2022" role="doc-biblioref">Pfitzmann et al. 2022</a>)</span> and proprietary datasets. The Docling pipeline uses page images at 72 dpi resolution. Bounding box proposals are post-processed to remove overlaps based on confidence and size and then intersected with text tokens to group them into meaningful units (e.g., paragraphs, section titles, tables).</p>
<p>RT-DETR (Real-Time DEtection TRansformer) is an object detection system using a hybrid encoder to process image features and IoU-aware query selection to focus on important parts of the image.</p>
<p><strong>Table Structure Recognition</strong></p>
<div id="fig-tableformer" class="quarto-float quarto-figure quarto-figure-center anchored" alt="TableFormer Architecture">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tableformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/tbm04.png" class="img-fluid figure-img" alt="TableFormer Architecture">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tableformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: TableFormer architecture. Source: <a href="https://github.com/DS4SD/docling-ibm-models">DS4SD/docling-ibm-models</a>
</figcaption>
</figure>
</div>
<p>The TableFormer model (a vision transformer) recovers table structure <a href="#fig-tableformer" class="quarto-xref">Figure&nbsp;3</a>. It predicts the logical row and column structure of a table based on an input image, determining which cells belong to column headers, row headers, or the table body. TableFormer handles tables with partial or no borderlines, empty cells, row or column spans, and other complexities.</p>
<p>The Docling pipeline feeds table objects detected in the layout analysis to the TableFormer model. TableFormer structure predictions are matched back to the PDF cells to avoid re-transcription of text in the table image.</p>
<p><strong>OCR (Optical Character Recognition)</strong></p>
<p>Docling optionally supports OCR for scanned PDFs or content in embedded bitmaps. Docling supports multiple OCR engines such as EasyOCR, Tesseract, RapidOCR, and OcrMac. By default, Docling feeds a high-resolution page image (216 dpi) to the OCR engine to capture small print details.</p>
<p><strong>Assembly and Post-processing</strong></p>
<p>In the final stage, Docling assembles all prediction results into a <code>DoclingDocument</code>, defined in the <code>docling-core</code> package. This document object is then passed through a post-processing model that augments features, such as:</p>
<ul>
<li>Document language detection</li>
<li>Reading order correction</li>
<li>Matching figures with captions</li>
<li>Labeling metadata (title, authors, references)</li>
</ul>
<p>The final output can be serialized to JSON or transformed into Markdown.</p>
<p>Additional post-processing steps can include:</p>
<ul>
<li>Classification of figures.</li>
<li>Identification of code blocks or formulas.</li>
<li>Annotation of pictures with LLMs (<a href="https://ds4sd.github.io/docling/examples/pictures_description_api/">example</a>).</li>
</ul>
<p>The <code>DoclingDocument</code> is a unified representation designed to encapsulate document structure and content in a standardized way. It’s a Pydantic datatype supporting text, tables, pictures, and more. It distinguishes between the main body and auxiliary elements (“furniture”). It retains layout information (bounding boxes) and provenance information. The <code>DoclingDocument</code> structure is organized into content items (texts, tables, pictures) and content structure (body, furniture, groups) <a href="#fig-docling-document" class="quarto-xref">Figure&nbsp;4</a>.</p>
<div id="fig-docling-document" class="quarto-float quarto-figure quarto-figure-center anchored" alt="DoclingDocument Hierarchy">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-docling-document-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/docling_doc_hierarchy_1.png" class="img-fluid figure-img" alt="DoclingDocument Hierarchy">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-docling-document-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: DoclingDocument structure. Source: <a href="https://ds4sd.github.io/docling/concepts/docling_document/">DS4SD/docling documentation</a>
</figcaption>
</figure>
</div>
</section>
<section id="sec-marker-pdf" class="level2">
<h2 class="anchored" data-anchor-id="sec-marker-pdf">Marker-PDF: Accurate PDF Conversion</h2>
<p><a href="https://github.com/VikParuchuri/marker">Marker-pdf</a> pipeline is another interesting option for PDF parsing. Raw extraction is done by <a href="https://github.com/VikParuchuri/pdftext">pdftext</a>, which is based on pypdfium2. Then, it uses Surya <a href="https://github.com/VikParuchuri/surya">Surya GitHub</a>. Surya is a document OCR toolkit that performs:</p>
<ul>
<li>OCR in 90+ languages.</li>
<li>Line-level text detection in any language.</li>
<li>Layout analysis (table, image, header, etc. detection).</li>
<li>Reading order detection.</li>
<li>Table recognition (detecting rows/columns).</li>
<li>LaTeX OCR.</li>
</ul>
<p>The JSON output format from Surya is illustrated in <a href="#lst-json-surya" class="quarto-xref">Listing&nbsp;2</a>. This structured output includes detailed information about page dimensions, blocks of text, and individual spans with their corresponding bounding boxes, font information, and text content. Marker itself converts PDFs and images to markdown, JSON, and HTML. The key features of Marker include:</p>
<ul>
<li>Supports a range of documents in all languages.</li>
<li>Formats tables, forms, equations, links, references, and code blocks.</li>
<li>Extracts and saves images along with the markdown.</li>
<li>Removes headers/footers/other artifacts.</li>
<li>Easily extensible with custom formatting and logic.</li>
<li>Optionally boosts accuracy with an LLM.</li>
<li>Works on GPU, CPU, or MPS.</li>
</ul>
<div id="lst-json-surya" class="json listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-json-surya-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;2: Example of Surya JSON output
</figcaption>
<div aria-describedby="lst-json-surya-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="lst-json-surya"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="lst-json-surya-1"><a href="#lst-json-surya-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span></span>
<span id="lst-json-surya-2"><a href="#lst-json-surya-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span></span>
<span id="lst-json-surya-3"><a href="#lst-json-surya-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"page"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span></span>
<span id="lst-json-surya-4"><a href="#lst-json-surya-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"bbox"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-5"><a href="#lst-json-surya-5" aria-hidden="true" tabindex="-1"></a>      <span class="dv">0</span><span class="ot">,</span></span>
<span id="lst-json-surya-6"><a href="#lst-json-surya-6" aria-hidden="true" tabindex="-1"></a>      <span class="dv">0</span><span class="ot">,</span></span>
<span id="lst-json-surya-7"><a href="#lst-json-surya-7" aria-hidden="true" tabindex="-1"></a>      <span class="fl">595.2760009765625</span><span class="ot">,</span></span>
<span id="lst-json-surya-8"><a href="#lst-json-surya-8" aria-hidden="true" tabindex="-1"></a>      <span class="fl">841.8900146484375</span></span>
<span id="lst-json-surya-9"><a href="#lst-json-surya-9" aria-hidden="true" tabindex="-1"></a>    <span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-surya-10"><a href="#lst-json-surya-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"width"</span><span class="fu">:</span> <span class="dv">596</span><span class="fu">,</span></span>
<span id="lst-json-surya-11"><a href="#lst-json-surya-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"height"</span><span class="fu">:</span> <span class="dv">842</span><span class="fu">,</span></span>
<span id="lst-json-surya-12"><a href="#lst-json-surya-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"rotation"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span></span>
<span id="lst-json-surya-13"><a href="#lst-json-surya-13" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"blocks"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-14"><a href="#lst-json-surya-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">{</span></span>
<span id="lst-json-surya-15"><a href="#lst-json-surya-15" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"lines"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-16"><a href="#lst-json-surya-16" aria-hidden="true" tabindex="-1"></a>          <span class="fu">{</span></span>
<span id="lst-json-surya-17"><a href="#lst-json-surya-17" aria-hidden="true" tabindex="-1"></a>            <span class="dt">"spans"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-18"><a href="#lst-json-surya-18" aria-hidden="true" tabindex="-1"></a>              <span class="fu">{</span></span>
<span id="lst-json-surya-19"><a href="#lst-json-surya-19" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"bbox"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-20"><a href="#lst-json-surya-20" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">36.14179992675781</span><span class="ot">,</span></span>
<span id="lst-json-surya-21"><a href="#lst-json-surya-21" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">99.6307373046875</span><span class="ot">,</span></span>
<span id="lst-json-surya-22"><a href="#lst-json-surya-22" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">481.22967529296875</span><span class="ot">,</span></span>
<span id="lst-json-surya-23"><a href="#lst-json-surya-23" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">131.6307373046875</span></span>
<span id="lst-json-surya-24"><a href="#lst-json-surya-24" aria-hidden="true" tabindex="-1"></a>                <span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-surya-25"><a href="#lst-json-surya-25" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"text"</span><span class="fu">:</span> <span class="st">"Pushing through undercurrents"</span><span class="fu">,</span></span>
<span id="lst-json-surya-26"><a href="#lst-json-surya-26" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"rotation"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span></span>
<span id="lst-json-surya-27"><a href="#lst-json-surya-27" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"font"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-json-surya-28"><a href="#lst-json-surya-28" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"name"</span><span class="fu">:</span> <span class="st">"OpenSans-Light"</span><span class="fu">,</span></span>
<span id="lst-json-surya-29"><a href="#lst-json-surya-29" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"flags"</span><span class="fu">:</span> <span class="dv">524320</span><span class="fu">,</span></span>
<span id="lst-json-surya-30"><a href="#lst-json-surya-30" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"size"</span><span class="fu">:</span> <span class="dv">1</span><span class="fu">,</span></span>
<span id="lst-json-surya-31"><a href="#lst-json-surya-31" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"weight"</span><span class="fu">:</span> <span class="dv">240</span></span>
<span id="lst-json-surya-32"><a href="#lst-json-surya-32" aria-hidden="true" tabindex="-1"></a>                <span class="fu">},</span></span>
<span id="lst-json-surya-33"><a href="#lst-json-surya-33" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"char_start_idx"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span></span>
<span id="lst-json-surya-34"><a href="#lst-json-surya-34" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"char_end_idx"</span><span class="fu">:</span> <span class="dv">28</span><span class="fu">,</span></span>
<span id="lst-json-surya-35"><a href="#lst-json-surya-35" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"url"</span><span class="fu">:</span> <span class="st">""</span></span>
<span id="lst-json-surya-36"><a href="#lst-json-surya-36" aria-hidden="true" tabindex="-1"></a>              <span class="fu">}</span><span class="ot">,</span></span>
<span id="lst-json-surya-37"><a href="#lst-json-surya-37" aria-hidden="true" tabindex="-1"></a>              <span class="fu">{</span></span>
<span id="lst-json-surya-38"><a href="#lst-json-surya-38" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"bbox"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-39"><a href="#lst-json-surya-39" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">466.78369140625</span><span class="ot">,</span></span>
<span id="lst-json-surya-40"><a href="#lst-json-surya-40" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">125.09466552734375</span><span class="ot">,</span></span>
<span id="lst-json-surya-41"><a href="#lst-json-surya-41" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">466.78369140625</span><span class="ot">,</span></span>
<span id="lst-json-surya-42"><a href="#lst-json-surya-42" aria-hidden="true" tabindex="-1"></a>                  <span class="fl">125.09466552734375</span></span>
<span id="lst-json-surya-43"><a href="#lst-json-surya-43" aria-hidden="true" tabindex="-1"></a>                <span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-surya-44"><a href="#lst-json-surya-44" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"text"</span><span class="fu">:</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span><span class="fu">,</span></span>
<span id="lst-json-surya-45"><a href="#lst-json-surya-45" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"rotation"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span></span>
<span id="lst-json-surya-46"><a href="#lst-json-surya-46" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"font"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-json-surya-47"><a href="#lst-json-surya-47" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"name"</span><span class="fu">:</span> <span class="st">""</span><span class="fu">,</span></span>
<span id="lst-json-surya-48"><a href="#lst-json-surya-48" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"flags"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span></span>
<span id="lst-json-surya-49"><a href="#lst-json-surya-49" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"size"</span><span class="fu">:</span> <span class="dv">1</span><span class="fu">,</span></span>
<span id="lst-json-surya-50"><a href="#lst-json-surya-50" aria-hidden="true" tabindex="-1"></a>                  <span class="dt">"weight"</span><span class="fu">:</span> <span class="dv">-1</span></span>
<span id="lst-json-surya-51"><a href="#lst-json-surya-51" aria-hidden="true" tabindex="-1"></a>                <span class="fu">},</span></span>
<span id="lst-json-surya-52"><a href="#lst-json-surya-52" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"char_start_idx"</span><span class="fu">:</span> <span class="dv">29</span><span class="fu">,</span></span>
<span id="lst-json-surya-53"><a href="#lst-json-surya-53" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"char_end_idx"</span><span class="fu">:</span> <span class="dv">30</span><span class="fu">,</span></span>
<span id="lst-json-surya-54"><a href="#lst-json-surya-54" aria-hidden="true" tabindex="-1"></a>                <span class="dt">"url"</span><span class="fu">:</span> <span class="st">""</span></span>
<span id="lst-json-surya-55"><a href="#lst-json-surya-55" aria-hidden="true" tabindex="-1"></a>              <span class="fu">}</span></span>
<span id="lst-json-surya-56"><a href="#lst-json-surya-56" aria-hidden="true" tabindex="-1"></a>            <span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-surya-57"><a href="#lst-json-surya-57" aria-hidden="true" tabindex="-1"></a>            <span class="dt">"bbox"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="lst-json-surya-58"><a href="#lst-json-surya-58" aria-hidden="true" tabindex="-1"></a>              <span class="fl">36.14179992675781</span><span class="ot">,</span></span>
<span id="lst-json-surya-59"><a href="#lst-json-surya-59" aria-hidden="true" tabindex="-1"></a>              <span class="fl">99.6307373046875</span><span class="ot">,</span></span>
<span id="lst-json-surya-60"><a href="#lst-json-surya-60" aria-hidden="true" tabindex="-1"></a>              <span class="fl">481.22967529296875</span><span class="ot">,</span></span>
<span id="lst-json-surya-61"><a href="#lst-json-surya-61" aria-hidden="true" tabindex="-1"></a>              <span class="fl">131.6307373046875</span></span>
<span id="lst-json-surya-62"><a href="#lst-json-surya-62" aria-hidden="true" tabindex="-1"></a>            <span class="ot">]</span></span>
<span id="lst-json-surya-63"><a href="#lst-json-surya-63" aria-hidden="true" tabindex="-1"></a>          <span class="fu">}</span></span>
<span id="lst-json-surya-64"><a href="#lst-json-surya-64" aria-hidden="true" tabindex="-1"></a>        <span class="ot">]</span><span class="fu">,</span></span>
<span id="lst-json-surya-65"><a href="#lst-json-surya-65" aria-hidden="true" tabindex="-1"></a><span class="er">...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
</section>
<section id="sec-mineru" class="level2">
<h2 class="anchored" data-anchor-id="sec-mineru">MinerU: Multi-Module Document Parsing</h2>
<div id="fig-mineru-pipeline" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Overview of the MinerU framework processing workflow.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mineru-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/minerU_pipeline.png" class="img-fluid figure-img" alt="Overview of the MinerU framework processing workflow.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mineru-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Overview of the MinerU framework processing workflow.
</figcaption>
</figure>
</div>
<p>MinerU is a multi-module document parsing framework that uses a multi-stage approach, employing various document parsing models to process document images. The code repository is available at the <a href="https://github.com/opendatalab/MinerU">MinerU GitHub Repository</a>, and technical details can be found in the reference paper <span class="citation" data-cites="wang2024mineruopensourcesolutionprecise">(<a href="#ref-wang2024mineruopensourcesolutionprecise" role="doc-biblioref">Wang et al. 2024</a>)</span>. MinerU provides source code, models, and documentation for parsing various document formats efficiently.</p>
<p>The MinerU framework processing workflow (<a href="#fig-mineru-pipeline" class="quarto-xref">Figure&nbsp;5</a>) consists of four stages:</p>
<ol type="1">
<li><em>Document Preprocessing</em>: Uses PyMuPDF to read PDF files, filters out unprocessable files, and extracts PDF metadata (parseability, language type, page dimensions).</li>
<li><em>Document Content Parsing</em>: Employs the PDF-Extract-Kit library for layout analysis (layout and formula detection). Applies different recognizers to various regions: OCR for text and titles, formula recognition for formulas, and table recognition for tables.</li>
<li><em>Document Content Post-Processing</em>: Removes invalid regions, stitches content according to regional positioning, and obtains positioning, content, and sorting information for different document regions.</li>
<li><em>Format Conversion</em>: Generates user-required formats, such as Markdown, for subsequent use.</li>
</ol>
<p><strong>Document Preprocessing</strong></p>
<p>This stage focuses on filtering unprocessable PDFs and obtaining PDF metadata:</p>
<ul>
<li><em>Language Identification</em>: Currently processes Chinese and English documents.</li>
<li><em>Content Garbled Detection</em>: Identifies text-based PDFs with garbled text.</li>
<li><em>Scanned PDF Identification</em>: Distinguishes between text-based and scanned PDFs.</li>
<li><em>Page Metadata Extraction</em>: Extracts document metadata such as total page count, page dimensions, and other attributes.</li>
</ul>
<p><strong>Document Content Parsing</strong></p>
<p>MinerU uses the PDF-Extract-Kit model library to detect different types of regions and recognize their content:</p>
<ul>
<li><em>Layout Analysis</em>: Identifies different types of elements and their regions on a page.</li>
<li><em>Formula Detection</em>: Detects inline and displayed formulas.</li>
<li><em>Formula Recognition</em>: Recognizes formula images into LaTeX source code using the UniMERNet model.</li>
<li><em>Table Recognition</em>: Extracts tabular data from visual table images using TableMaster and StructEqTable.</li>
<li><em>OCR</em>: Applies Paddle-OCR to recognize text regions.</li>
</ul>
<p><strong>Document Content Post-Processing</strong></p>
<p>This stage addresses content ordering by handling the relationships between Bounding Boxes (BBoxes):</p>
<ul>
<li><em>Containment Relationships</em>: Removes formulas and text blocks contained within image and table regions.</li>
<li><em>Partial Overlap Relationships</em>: Shrinks partially overlapping text boxes and ensures the integrity of text when overlapping with tables/images.</li>
<li><em>Segmentation Algorithm</em>: Divides the page into regions based on human reading order (“top to bottom, left to right”).</li>
</ul>
<p><strong>Models Overview</strong></p>
<div id="tbl-mineru-models" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-mineru-models-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: MinerU models overview
</figcaption>
<div aria-describedby="tbl-mineru-models-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 40%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Task Type</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Models</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Layout Detection</td>
<td style="text-align: left;">Locate different elements in a document: including images, tables, text, titles, formulas</td>
<td style="text-align: left;">DocLayout-YOLO_ft, YOLO-v10_ft, LayoutLMv3_ft</td>
</tr>
<tr class="even">
<td style="text-align: left;">Formula Detection</td>
<td style="text-align: left;">Locate formulas in documents: including inline and block formulas</td>
<td style="text-align: left;">YOLOv8_ft</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Formula Recognition</td>
<td style="text-align: left;">Recognize formula images into LaTeX source code</td>
<td style="text-align: left;">UniMERNet</td>
</tr>
<tr class="even">
<td style="text-align: left;">OCR</td>
<td style="text-align: left;">Extract text content from images (including location and recognition)</td>
<td style="text-align: left;">PaddleOCR</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Table Recognition</td>
<td style="text-align: left;">Recognize table images into corresponding source code (LaTeX/HTML/Markdown)</td>
<td style="text-align: left;">PaddleOCR+TableMaster, StructEqTable</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-comparing-libraries" class="level1">
<h1>Comparing PDF Parsing Libraries</h1>
<p>Comparing PDF parsing libraries involves evaluating several factors: ease of use, functionality, performance. This section aims to provide an overview of the comparative performance of the parsing options in the context of different PDF types.</p>
<p>This analysis provides a practical comparison of several PDF parsing libraries, with a unique focus on visualizing the differences between PDF input and Markdown output. The complete code and implementation details are available in the <a href="https://github.com/nbrosse/pdf-parsing">pdf-parsing repository</a>, and an interactive demo can be accessed through the <a href="https://huggingface.co/spaces/nbrosse/pdf-parsing-demo">pdf-parsing-demo</a> Hugging Face Space.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>All code is available at the <a href="https://github.com/nbrosse/pdf-parsing">pdf-parsing repository</a>.</p>
</div>
</div>
<section id="pdf-sample-dataset" class="level2">
<h2 class="anchored" data-anchor-id="pdf-sample-dataset">PDF Sample Dataset</h2>
<p>We test the different PDF parsing options on a small but diverse dataset of PDFs. These PDFs are available at the following link: <a href="https://github.com/nbrosse/pdf-parsing/tree/main/pdfs">PDF Parsing Dataset</a>. The dataset contains different types of PDFs to cover various difficulties faced by PDF parsers:</p>
<ul>
<li>Slides</li>
<li>Image-only PDFs (requiring OCR)</li>
<li>Reports</li>
<li>Tables</li>
</ul>
<p>The PDF files located in the <code>pdfs</code> directory were sourced from the following locations:</p>
<ul>
<li><code>XC9500_CPLD_Family-1-4.pdf</code>: Downloaded from <a href="https://media.digikey.com/pdf/Data%20Sheets/AMD/XC9500_CPLD_Family.pdf" class="uri">https://media.digikey.com/pdf/Data%20Sheets/AMD/XC9500_CPLD_Family.pdf</a></li>
<li><code>2023-conocophillips-aim-presentation-1-7.pdf</code>: Downloaded from <a href="https://static.conocophillips.com/files/2023-conocophillips-aim-presentation.pdf" class="uri">https://static.conocophillips.com/files/2023-conocophillips-aim-presentation.pdf</a></li>
</ul>
<p>The following four PDF files are sourced from the <a href="https://www.eyelevel.ai/post/most-accurate-rag">RAG blog benchmark</a>, specifically from the associated <a href="https://drive.google.com/drive/u/0/folders/1l45ljrGfOKsiNFh8QPji2eBAd2hOB51c">Google Drive folder</a>:</p>
<ul>
<li><code>gx-iif-open-data.pdf</code></li>
<li><code>deloitte-tech-risk-sector-banking.pdf</code></li>
<li><code>life-sciences-smart-manufacturing-services-peak-matrix-assessment-2023.pdf</code></li>
<li><code>dttl-tax-technology-report-2023.pdf</code></li>
</ul>
</section>
<section id="qualitative-results" class="level2">
<h2 class="anchored" data-anchor-id="qualitative-results">Qualitative Results</h2>
<p><strong>Note:</strong> The following results are based on a limited set of tests and should be considered indicative rather than scientifically rigorous.</p>
<div class="callout-info">
<p>You can directly compare the output Markdown results at the Hugging Face Space demo: <a href="https://huggingface.co/spaces/nbrosse/pdf-parsing-demo">pdf-parsing-demo</a>.</p>
</div>
<p><a href="https://github.com/DS4SD/docling">Docling</a> provides decent results for text extraction, layout analysis, and table recognition. The OCR support is also a valuable addition for scanned PDFs. Very recently, it provides support for image description <a href="https://ds4sd.github.io/docling/examples/pictures_description_api/">example</a>, which is a very promising feature.</p>
<div id="fig-docling-streamlit" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Docling parsing results">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-docling-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/docling_streamlit.png" class="img-fluid figure-img" alt="Docling parsing results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-docling-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Docling parsing results
</figcaption>
</figure>
</div>
<p><a href="https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/">LlamaParse</a> in default mode also provides good results. It provides descriptions of charts and images and is able to extract tables. However, the quality of the chart and image descriptions is not top-tier. It is also a closed-source solution.</p>
<div id="fig-llamaparse-streamlit" class="quarto-float quarto-figure quarto-figure-center anchored" alt="LlamaParse parsing results">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-llamaparse-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/llamaparse_streamlit.png" class="img-fluid figure-img" alt="LlamaParse parsing results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-llamaparse-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: LlamaParse parsing results
</figcaption>
</figure>
</div>
<p><a href="https://github.com/VikParuchuri/marker">Marker</a> provides good results and a description of the images using Gemini.</p>
<div id="fig-marker-streamlit" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Marker parsing results">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-marker-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/marker_streamlit.png" class="img-fluid figure-img" alt="Marker parsing results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-marker-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Marker parsing results
</figcaption>
</figure>
</div>
<p><a href="https://pymupdf.readthedocs.io/en/latest/">PyMuPDF</a> in default mode is a more raw extraction approach, parsing the raw content. The other libraries tend to build upon more fundamental extraction libraries such as PyMuPDF. The results generally require further refinement.</p>
<div id="fig-pymupdf-streamlit" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Pymupdf parsing results">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pymupdf-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/pymupdf_streamlit.png" class="img-fluid figure-img" alt="Pymupdf parsing results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pymupdf-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Pymupdf parsing results
</figcaption>
</figure>
</div>
<p><a href="https://ai.google.dev/aistudio">Gemini</a> is very good at parsing the content and providing a description of the images. It is versatile and effective. However, it is closed source.</p>
<div id="fig-gemini-streamlit" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Gemini parsing results">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gemini-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/gemini_streamlit.png" class="img-fluid figure-img" alt="Gemini parsing results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gemini-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Gemini parsing results
</figcaption>
</figure>
</div>
<div id="fig-gemini-streamlit-2" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Gemini parsing results suppl.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gemini-streamlit-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/gemini_streamlit_2.png" class="img-fluid figure-img" alt="Gemini parsing results suppl.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gemini-streamlit-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Gemini parsing results (suppl.)
</figcaption>
</figure>
</div>
<p><a href="https://github.com/opendatalab/MinerU">MinerU</a> is not part of the app because it is not easy to split the output by page, and tables are under HTML format. However, the results are good, and the layout is very good. It doesn’t support image description. MinerU is a very promising library.</p>
<div id="fig-mineru-streamlit" class="quarto-float quarto-figure quarto-figure-center anchored" alt="MinerU parsing results">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mineru-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/mineru_streamlit.png" class="img-fluid figure-img" alt="MinerU parsing results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mineru-streamlit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: MinerU parsing results
</figcaption>
</figure>
</div>
<p>We tested <a href="https://docs.unstructured.io/welcome">unstructured</a> (free version), which did not produce satisfying results.</p>
<p><a href="https://github.com/microsoft/markitdown">Markitdown</a> is a very new library that we did not test. It seems to rely on ad-hoc solutions and is simply an aggregator of solutions.</p>
<p>We also tested (not extensively) some cloud-based solutions for PDF parsing such as <a href="https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/">Adobe PDF Extract API</a>, <a href="https://aws.amazon.com/textract/">AWS Textract</a> and <a href="https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence">Azure AI Document intelligence</a> but we were not convinced by the first results. Apparently, they seem to be very good at extracting for large quantity of pdf following the same template.</p>
<p>In terms of table extraction capabilities, we tested Camelot, a specialized library specifically designed for extracting tables from PDFs. Camelot excels at handling both lattice and stream type tables, making it particularly effective for complex table extraction tasks. The library is well-documented and maintained, with comprehensive documentation available on their <a href="https://github.com/camelot-dev/camelot">GitHub repository</a>. The results were good for table extraction. Camelot is a dedicated library for tables.</p>
<p><strong>Conclusion</strong>: The choice of PDF parsing library depends on the specific requirements of the task at hand. or general-purpose parsing with a strong emphasis on image understanding, consider Gemini. However, be aware that this is a closed-source solution. If an open-source solution is preferred, Docling, Marker and MinerU are strong contenders. For tasks requiring specialized table extraction, Camelot is a reliable choice.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This exploration of PDF parsing for Large Language Model (LLM) input has revealed a diverse landscape of tools and techniques, each with its strengths and limitations. We’ve examined open-source libraries like Docling, MinerU, Marker and PyMuPDF, as well as closed-source solutions such as LlamaParse and direct parsing with Gemini.</p>
<p>Our qualitative comparison, demonstrated through the <a href="https://huggingface.co/spaces/nbrosse/pdf-parsing-demo">pdf-parsing-demo</a>, highlights the trade-offs between accuracy, functionality, and ease of use. While closed-source solutions like Gemini and LlamaParse often provide superior out-of-the-box performance, especially in areas like image description and table extraction, they come with the constraints of licensing and limited customization. Open-source libraries like Docling and MinerU offer greater flexibility but may require more effort to achieve comparable results.</p>
<p>The choice of PDF parsing approach ultimately hinges on the specific requirements of the LLM application. Factors to consider include:</p>
<ul>
<li><strong>Accuracy and Completeness:</strong> How critical is it to extract all the text and data from the PDF accurately?</li>
<li><strong>Layout Fidelity:</strong> Is preserving the original layout of the document important?</li>
<li><strong>Image and Table Understanding:</strong> Are there significant images or tables that need to be extracted and understood?</li>
<li><strong>Open Source vs.&nbsp;Closed Source:</strong> Does the project require an open-source solution for licensing or customization reasons?</li>
<li><strong>Complexity of PDFs:</strong> Does the typical PDF being parsed have many images, tables, or just general text?</li>
</ul>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-auer2024doclingtechnicalreport" class="csl-entry" role="listitem">
Auer, Christoph, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Nikolaos Livathinos, Panos Vagenas, Cesar Berrospi Ramis, et al. 2024. <span>“Docling Technical Report.”</span> <a href="https://arxiv.org/abs/2408.09869">https://arxiv.org/abs/2408.09869</a>.
</div>
<div id="ref-livathinos2025doclingefficientopensourcetoolkit" class="csl-entry" role="listitem">
Livathinos, Nikolaos, Christoph Auer, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panos Vagenas, Cesar Berrospi Ramis, et al. 2025. <span>“Docling: An Efficient Open-Source Toolkit for AI-Driven Document Conversion.”</span> <a href="https://arxiv.org/abs/2501.17887">https://arxiv.org/abs/2501.17887</a>.
</div>
<div id="ref-nassar2022tableformertablestructureunderstanding" class="csl-entry" role="listitem">
Nassar, Ahmed, Nikolaos Livathinos, Maksym Lysak, and Peter Staar. 2022. <span>“TableFormer: Table Structure Understanding with Transformers.”</span> <a href="https://arxiv.org/abs/2203.01017">https://arxiv.org/abs/2203.01017</a>.
</div>
<div id="ref-Pfitzmann_2022" class="csl-entry" role="listitem">
Pfitzmann, Birgit, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar. 2022. <span>“DocLayNet: A Large Human-Annotated Dataset for Document-Layout Segmentation.”</span> In <em>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 3743–51. KDD ’22. ACM. <a href="https://doi.org/10.1145/3534678.3539043">https://doi.org/10.1145/3534678.3539043</a>.
</div>
<div id="ref-wang2024mineruopensourcesolutionprecise" class="csl-entry" role="listitem">
Wang, Bin, Chao Xu, Xiaomeng Zhao, Linke Ouyang, Fan Wu, Zhiyuan Zhao, Rui Xu, et al. 2024. <span>“MinerU: An Open-Source Solution for Precise Document Content Extraction.”</span> <a href="https://arxiv.org/abs/2409.18839">https://arxiv.org/abs/2409.18839</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/nbrosse\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>