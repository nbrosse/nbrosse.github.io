---
title: "PDF RAG"
author: "Nicolas Brosse"
date: "2025-03-10"
categories: [deep learning, LLM, RAG]
bibliography: pdf-rag-references.bib
description: "PDF RAG: Exploring techniques for processing PDF documents with Language Models, including raw conversion, reformatting, and structure parsing."
---

In this blog post, we focus on RAG (Retrieval-Augmented Generation) specifically for PDF documents. We will study how PDFs can be processed for use with Language Models (LLMs). The code relies on [llama-index](https://docs.llamaindex.ai/en/stable/) package which is versatile but evolving rapidly and unstable.

PDFs are ubiquitous in businesses and throughout the human world. What's remarkable is the sheer diversity of PDF types we encounter. These range from reports of just a few pages to documents spanning hundreds of pages, generally including a table of contents. We also frequently deal with slide decks, or presentations, which are common in corporate settings. These can vary from just a few slides to dozens or even hundreds, often with their own unique tables of contents and organizational structures.

It's fascinating to consider how differently humans and computers process this information. Humans, when facing lengthy documents, generally tend to look at the table of contents and assess the document's overall structure to identify areas of interest.

However, machines, especially with page-by-page parsing, often lose the document's overall structure. One way to address this is to use embeddings and chunking, attempting to find similarities through embeddings or semantic similarity to identify potentially relevant chunks of information.

This highlights the core challenge of the method: the need to process data differently as a human than as a machine, particularly to gain a holistic view of the problem.

In @sec-metadata-structure, we delve into PDF metadata and structure extraction, focusing on the raw conversion process. We explore the challenges and limitations of raw conversion and the necessity of reformatting to improve document structure.

First, we'll examine PDF page parsing, particularly focusing on heading handling. This has led us to try raw conversions and reformatting with PDF parsing. The goal is to reformat by asking a large language model (LLM) to reprocess the document chunk by chunk, given that some documents can be very long. The aim is to provide a more comprehensive overview. We're using Gemini, which has a very large context, which makes this approach quite helpful. We are observing an improvement in the markdown formatting, particularly with better title identification. It's not always perfect, but there's a more effective segmentation based on titles and markdown, resulting in better adherence to the overall document structure compared to what we had before.

This makes it easier to have a structure a bit more coherent when you cut through markdowns, especially in reports. For slides, we would cut in a very different way. We will use page page page cutting, trying to identify the summaries.

::: callout-note
**llama-index:** A powerful framework for building LLM applications. [llama-index](https://docs.llamaindex.ai/en/stable/)

**pdf-rag GitHub Repo & HF Space Demo:** Check out the code and a demo. - [pdf-rag GitHub Repo](https://github.com/nbrosse/pdf-rag) - [HF Space Demo for PDF Metadata](https://huggingface.co/spaces/nicolasb92/pdf-rag-metadata-demo)
:::

# PDF Metadata and Structure Extraction {#sec-metadata-structure}

We first convert PDF to markdown in @sec-pdf-markdown, then reformat the markdown to improve the structure. The goal is to create a more coherent and structured representation of the document content. This process involves several steps, including raw conversion, reformatting, and structure parsing.

## PDF to Markdown Conversion {#sec-pdf-markdown}

For PDF to Markdown conversion, we refer to the related blog post [PDF parsing for LLM Input](https://nbrosse.github.io/posts/pdf-parsing/pdf-parsing.html) which describes different methods to parse PDFs for LLM input.

For RAG applications with PDFs, we'll focus on using Vision Language Models (VLMs) for PDF-to-Markdown conversion. As discussed in the related blog post [PDF parsing for LLM Input](https://nbrosse.github.io/posts/pdf-parsing/pdf-parsing.html), VLMs offer a straightforward and effective solution. While the approach is more expensive than basic text extraction, it provides valuable capabilities like image description integration. Similar to [LlamaParse](https://docs.cloud.llamaindex.ai/llamaparse/getting_started) but with more flexibility, our implementation allows:

-   Full control over model selection
-   Choice of different API providers
-   End-to-end process management

File `src/pdf_rag/readers.py`: The code implements a `VLMPDFReader` class that uses Vision Language Models (VLMs) to convert PDF documents to markdown format. Here's how it works.

**Key Features**

-   Uses both Gemini and Mistral models for processing.
-   Supports both single PDFs and batch processing.
-   Includes a caching mechanism to avoid reprocessing.
-   Handles API rate limiting and retries.
-   Processes PDFs page by page with parallel execution.

**Architecture**

The conversion process follows these steps:

1.  **Initialization**
    -   Sets up API clients for Gemini and Mistral.
    -   Validates API keys and cache directory.
    -   Loads conversion template.
2.  **PDF Processing**
    -   Loads PDF file using `PdfReader`.
    -   Processes each page individually.
    -   Converts PDF pages to images for VLM processing.
3.  **VLM Processing Pipeline**
    -   First attempts conversion with Gemini.
    -   Falls back to Mistral if Gemini returns "RECITATION".
    -   Uses a template to guide the conversion.
4.  **Output Generation**
    -   Combines processed pages.
    -   Adds page markers for reference.
    -   Caches results to avoid reprocessing.
    -   Returns document with metadata.

**Usage Example**

``` python
reader = VLMPDFReader(
    cache_dir="./cache",
    api_key_gemini="your_gemini_key",  # or use env var GEMINI_API_KEY
    api_key_mistral="your_mistral_key"  # or use env var MISTRAL_API_KEY
)

# Single file
doc = reader.load_data("path/to/document.pdf")

# Multiple files
docs = reader.load_data(["doc1.pdf", "doc2.pdf"])
```

Why do we use Gemini and Mistral models ?

**The "RECITATION" Error in Gemini API**

The RECITATION error in the Gemini API occurs when the model detects that it is generating content that closely resembles its training data, particularly copyrighted material. This error is designed to prevent the model from reproducing protected content verbatim. The issue arises unpredictably and can halt content generation mid-stream, leading to incomplete responses.

Key Points:

-   **Error Message**: "Content generation stopped. Reason: RECITATION."
-   **Cause**: The model identifies that the generated content is too similar to its training data, especially copyrighted material.
-   **Impact**: Stops content generation abruptly, leading to incomplete outputs.
-   **Unpredictability**: The error occurs randomly and is difficult to anticipate.
-   **Workarounds**: Some users have found temporary solutions, such as adjusting the API's temperature and topP parameters, or including specific instructions in the prompt to avoid recitation. However, these methods are not foolproof and may affect the quality of the generated content.

In this case of failure, we fall back to the Mistral model to parse the problematic pdf page.

Overall, the RECITATION error is a significant challenge for developers using the Gemini API, highlighting the tension between content safety and usability

`VLMPDFReader` is designed to be robust and efficient, with built-in caching and parallel processing capabilities to handle large documents or multiple files efficiently.

Here is the associated template prompt for the VLM.

<details>
<summary>Click to view template</summary>
<pre>
You are a specialized document transcription assistant converting PDF documents to Markdown format.
Your primary goal is to create an accurate, complete, and well-structured Markdown representation.

&ltinstructions>
1. Language and Content:
   - MAINTAIN the original document language throughout ALL content
   - ALL elements (headings, tables, descriptions) must use source language
   - Preserve language-specific formatting and punctuation
   - Do NOT translate any content

2. Text Content:
   - Convert all text to proper Markdown syntax
   - Use appropriate heading levels (# ## ###)
   - Preserve emphasis (bold, italic, underline)
   - Convert bullet points to Markdown lists (-, *, +)
   - Maintain original document structure and hierarchy

3. Visual Elements (CRITICAL):
   a. Tables:
      - MUST represent ALL data cells accurately in original language
      - Use proper Markdown table syntax |---|
      - Include header rows
      - Add caption above table: [Table X: Description] in document language

   b. Charts/Graphs:
      - Create detailed tabular representation of ALL data points
      - Include X/Y axis labels and units in original language
      - List ALL data series names as written
      - Add caption: [Graph X: Description] in document language

   c. Images/Figures:
      - Format as: ![Figure X: Detailed description](image_reference)
      - Describe key visual elements in original language
      - Include measurements/scales if present
      - Note any text or labels within images

4. Quality Requirements:
   - NO content may be omitted
   - Verify all numerical values are preserved
   - Double-check table column/row counts match original
   - Ensure all labels and legends are included
   - Maintain document language consistently throughout

5. Structure Check:
   - Begin each section with clear heading
   - Use consistent list formatting
   - Add blank lines between elements
   - Preserve original content order
   - Verify language consistency across sections
&lt/instructions>
</pre>
</details>

![Raw conversion](figures/md_raw_conversion.png){#fig-pdf-raw-conversion fig-alt="Raw conversion"}

We also have a `PDFDirectoryReader` class to provide batch processing capabilities for PDF files within a directory structure. It acts as a wrapper around the `VLMPDFReader`, adding directory handling and metadata extraction features.

**Key Features**

-   **Directory-based Processing**: Handles both single PDF files and directories containing multiple PDFs
-   **Metadata Extraction**: Automatically extracts and includes file metadata like:
    -   Creation date
    -   Last modified date
    -   File size
    -   File type
    -   Relative path information
-   **Configuration Management**:
    -   Validates directory paths and creates cache directories
    -   Manages API keys for both Gemini and Mistral models
    -   Supports environment variable configuration
-   **Parallel Processing**: Configurable number of workers for concurrent processing

**Usage Example**

``` python
reader = PDFDirectoryReader(
    root_dir="./documents",
    cache_dir="./cache",
    num_workers=4,
    show_progress=True
)

# Process single PDF file
docs = reader.load_data("documents/sample.pdf")

# Process directory of PDFs
docs = reader.load_data("documents/reports/")

# Async processing
docs = await reader.aload_data("documents/reports/")
```

**Difficulties and drawbacks of raw conversion**

The raw conversion process has several limitations and drawbacks that can affect the quality and accuracy of the output. Some of the key challenges include:

One of the main difficulties in PDF parsing is that it is generally done page by page, causing the loss of the overall document structure. We lose the appropriate headings that help retrieve the general structure of the document, and we end up with a very local and focused view. For example, when converting PDF to markdown, the heading structure specified by the markdown is generally incorrect - the headers and their levels don't correspond to what is expected.

We face an additional challenge because PDFs can be either portrait-formatted reports or landscape-formatted slides. In both cases, the PDF is processed page by page, resulting in the loss of the overall document structure. However, the processing approach may need to differ depending on whether we're dealing with slides or reports.

## PDF Reformatting {#sec-pdf-reformatting}

This has led us to try reformatting with PDF parsing. The goal is to reformat by asking a large language model (LLM) to reprocess the document chunk by chunk, given that some documents can be very long. The aim is to provide a more comprehensive overview. We're using Gemini, which has a very large context, which makes this approach quite helpful. We are observing an improvement in the markdown formatting, particularly with better title identification. It's not always perfect, but there's a more effective segmentation based on titles and markdown, resulting in better adherence to the overall document structure compared to what we had before.

This makes it easier to have a structure a bit more coherent when you cut through markdowns, especially in reports.

File `src/pdf_rag/transforms.py`: `ReformatMarkdownComponent` Class

The `ReformatMarkdownComponent` class reformats markdown content using the Gemini API. Here's a detailed breakdown of its functionality:

**Key Features**

1.  **Configuration Options**
    -   `max_iters`: Maximum iterations for reformatting (default: 50)
    -   `in_place`: Whether to modify nodes directly or create copies (default: True)
    -   `num_workers`: Number of concurrent workers (default: 4)
    -   `show_progress`: Display progress during processing (default: True)
2.  **Caching Mechanism**
    -   Stores reformatted content in `.reformatted.md` files
    -   Avoids reprocessing previously reformatted content
    -   Uses file path and cache directory from node metadata
3.  **Processing Pipeline**
    -   Handles individual nodes asynchronously
    -   Uses Jinja2 templates for content reformatting
    -   Supports both landscape and portrait formats
    -   Accumulates reformatted content iteratively

**Usage Example**

``` python
component = ReformatMarkdownComponent(
    api_key="your_gemini_key",  # or use env var GEMINI_API_KEY
    num_workers=4,
    show_progress=True
)

# Process nodes
processed_nodes = component(nodes)

# Async processing
processed_nodes = await component.acall(nodes)
```

The component is designed to improve document structure through:

-   **Heading Hierarchies**: Ensures proper nesting and levels (H1 -\> H2 -\> H3)
-   **Consistent Formatting**: Standardizes markdown syntax, lists, and spacing
-   **Content Preservation**: Maintains original language, technical details, and metadata
-   **Format Handling**: Supports both portrait (reports) and landscape (presentations) layouts
-   **Quality Checks**: Validates completeness and structure accuracy

Here is the associated template prompt for Gemini.

<details>
<summary>Click to view template</summary>
<pre>
&ltdocument>
{{ document }}
&lt/document>

{% if processed %}
&ltprocessed>
{{ processed }}
&lt/processed>
{% endif %}

You are a professional technical documentation editor specializing in markdown documents.
Your task is to transform the document into a well-structured markdown document with clear hierarchy and organization.

&ltinstructions>
1. Content Preservation (CRITICAL):
    - PRESERVE ALL original content without exception
    - Do not summarize or condense any information
    - Maintain all technical details, examples, and code snippets
    - Keep all original links, references, and citations
    - Preserve all numerical data and specifications
    {% if landscape %}
    - Preserve `---end page ...` markers
    {% endif %}

2. Document Structure:
    - Ensure exactly one H1 (#) title at the start
    - Use maximum 3 levels of headers (H1 -> H2 -> H3)
    - Avoid excessive nesting - prefer flatter structure
    - Group related sections under appropriate headers
    - If an existing TOC is present, maintain and update it
    - Only create new TOC if none exists

3. Formatting Standards:
    - Use consistent bullet points/numbering
    - Format code blocks with appropriate language tags
    - Properly format links and references
    - Use tables where data is tabular
    - Include blank lines between sections

4. Quality Checks:
    - Compare final document with original for completeness
    - Verify all technical information is preserved
    - Ensure all examples remain intact
    - Maintain all nuances and specific details

5. Metadata & Front Matter:
    - Include creation/update dates if present
    - Preserve author information
    - Maintain any existing tags/categories
&lt/instructions>

{% if processed %}
Please continue reformatting from where it was left off, maintaining consistency with the processed portion.
Ensure NO content is omitted - preserve everything from the original document.
All sections should seamlessly integrate with the existing structure.
End your response with &ltend>.
{% else %}
Provide the complete reformatted document following the above guidelines.
WARNING: Do not omit ANY content - preserve everything from the original document.
Ensure all sections are properly nested and formatted.
End your response with &ltend>.
{% endif %}
</pre>
</details>

![Reformatted](figures/md_raw_reformatted_conversion.png){#fig-markdown-reformatted fig-alt="Reformatted"}

## PDF Metadata Extraction {#sec-pdf-metadata}

Once we've converted and reformatted the PDF content into markdown format using Vision Language Models (VLMs), the next step is extracting valuable metadata from the documents. This section explores a series of specialized extractors built on the LlamaIndex framework, each designed to capture specific aspects of PDF documents:

-   Document context (author, date, language)
-   Table of contents (both extraction and creation)
-   Page structure (especially for presentations)
-   Document hierarchy and relationships

These extractors work together to create a comprehensive metadata layer that enhances document searchability and understanding.

File: `src/pdf_rag/extractors.py`

The `GeminiBaseExtractor` serves as the foundation for all extractors, providing:

-   Gemini API integration with configurable temperature and model selection
-   API key validation and management
-   Abstract interface for extraction operations
-   Parallel processing capabilities

### 1. `ContextExtractor`

Extracts contextual information from documents:

-   Processes document content using a specialized template
-   Returns structured JSON with document context
-   Handles parallel processing of multiple nodes

<details>
<summary>Click to view template prompt for Gemini</summary>
<pre>
&ltdocument>
{{ document }}
&lt/document>

Please analyze the above document and provide output in the following JSON format:

{
    "author": "detected_author",
    "publication_date": "YYYY-MM-DD",
    "language": "detected_language in ISO 639-1 language code format",
    "document_type": "type_if_identifiable"
    "themes": [
        {
            "name": "Theme name",
            "description": "Brief explanation"
        }
    ],
    "entities": [
            {
                "name": "Entity name",
                "role": "Role/significance"
            }
    ],
    "time_periods": [
        {
            "start_date": "YYYY-MM-DD",
            "end_date": "YYYY-MM-DD",
            "period_description": "Description of events/developments in this timeframe",
            "is_approximate": boolean,
        }
    ],
    "keywords": [
        "keyword1",
        "keyword2"
    ],
    "summary": "Concise summary text focusing on main points"
}

Note: Keep descriptions concise and factual.
If an item is missing, answer with "".
Answer in the language of the document.
</pre>
</details>

### 2. `TableOfContentsExtractor`

Extracts existing tables of contents from documents:

-   Focuses on the first 10 pages by default
-   Supports both portrait and landscape formats
-   Returns an empty string if no TOC is found
-   Uses a templated approach for extraction

<details>
<summary>Click to view template prompt for Gemini</summary>
<pre>
&ltdoc>
{{ doc }}
&lt/doc>

{% if format == 'landscape' %}
Extract the table of contents (TOC) from the document if present and specify the page number where the table of contents is located.
The table of contents, if it exists, is located on a single page.
Note that each page in the document ends with a marker '--- end page n' where n is the page number.

Output format:
- If a table of contents exists:
  First line: "Table of contents found on page X"
  Following lines: Complete TOC with its original structure and hierarchy
- If no table of contents exists: Respond with exactly "&ltnone>"
{% else %}
Extract the table of contents (TOC) from the document if it exists.
IMPORTANT: the table of contents must be contained in consecutive lines in the source document itself.

Output format:
- If a table of contents exists: complete TOC with its original structure and hierarchy
- If no table of contents exists: Respond with exactly "&ltnone>"
{% endif %}
</pre>
</details>

### 3. `TableOfContentsCreator`

Creates new tables of contents:

-   **Portrait Mode**:
    -   Analyzes markdown headers
    -   Includes line numbers for reference
    -   Requires reformatted content
-   **Landscape Mode**:
    -   Generates TOC using Gemini
    -   Includes a validation step
    -   Two-phase process: draft and check

<details>
<summary>Click to view draft template prompt for Gemini</summary>
<pre>
&ltdoc>
{{ doc }}
&lt/doc>

Generate a hierarchical table of contents for the slides deck above by:

1. IDENTIFY SECTION BREAKS
- Section breaks are marked by "--- end page {n}" where n is the page number

2. EXTRACT SECTION INFO
- Get the title text from each section break page
- Record the corresponding page number
- Validate that page numbers are unique and ascending

3. FORMAT OUTPUT
Format each entry as:
# {Section Title} (Page {n})

Example output:
# Introduction (Page 1)
# Key Concepts (Page 5)
# Implementation (Page 12)

Requirements:
- Page numbers must be unique and sequential
- Ignore any formatting in the section titles

The TOC should help readers quickly navigate the main sections of the deck.
</pre>
</details>

<details>
<summary>Click to view check template prompt for Gemini</summary>
<pre>
&lttoc>
{{ toc }}
&lt/toc>

Generate a standardized table of contents following these rules:

1. FORMAT REQUIREMENTS
- Each entry: "# {Title} (Page {n})"
- Page numbers must be integers in parentheses
- One entry per line, no blank lines
- Preserve original markdown formatting in titles
- Page numbers ascending order

2. VALIDATION
- Reject duplicate page numbers
- Reject duplicate titles
- Page numbers must exist and be > 0
- Title cannot be empty

Example valid output:
# Executive Summary (Page 1)
# Market Analysis (Page 3)
# Financial Projections (Page 7)
</pre>
</details>

### 4. `LandscapePagesExtractor`

Specialized for landscape (presentation) documents:

-   Requires an existing TOC (extracted or created)
-   Processes document content page by page
-   Uses template-based extraction
-   Returns structured page information

<details>
<summary>Click to view template prompt for Gemini</summary>
<pre>
&ltdoc>
{{ doc }}
&lt/doc>

&lttoc>
{{ toc }}
&lt/toc>

Extract and list all pages from the slides deck in &ltdoc>, using the table of contents in &lttoc> as reference.

Rules:
1. Format each line exactly as: Page N : [title]
2. List pages in ascending numerical order (1, 2, 3...)
3. When a page has no title, use the title from its preceding page
4. Include all pages, even those without content

Example:
Page 1 : Introduction
Page 2 : Market Analysis
Page 3 : Market Analysis
Page 4 : Key Findings
</pre>
</details>

### 5. `StructureExtractor`

Handles document structure analysis:

-   **Portrait Mode**:
    -   Uses the created TOC for structure
    -   Simple structure representation
-   **Landscape Mode**:
    -   Combines TOC and page information
    -   Creates a comprehensive structure
    -   Requires both TOC and page metadata

<details>
<summary>Click to view template prompt for Gemini</summary>
<pre>
&lttoc>
{{ toc }}
&lt/toc>

&ltpages>
{{ pages }}
&lt/pages>

Analyze the table of contents (TOC) in &lttoc> and the pages of the slides deck provided in &ltpages>.
Group the pages under their corresponding TOC sections using this format:

# [TOC Section]
- Page X : [Full Page Title]
- Page Y : [Full Page Title]

Rules:
- Each TOC section should have an appropriate level heading with #, ##, or ###.
- List all pages that belong under each section
- Maintain original page numbers and full titles
- Include pages even if their titles are slightly different from TOC entries
- Group subsections under their main section
- List pages in numerical order within each section
- Don't omit any pages
- If a page doesn't clearly fit under a TOC section, place it under "Other Pages"

Example:
# Introduction
- Page 1 : Welcome Slide
- Page 2 : Project Overview

# Key Findings
- Page 3 : Financial Results
- Page 4 : Market Analysis
</pre>
</details>

**Usage Example**

``` python
# Initialize extractor
extractor = TableOfContentsExtractor(
    api_key="your_gemini_key",  # or use env var GEMINI_API_KEY
    head_pages=10,
    temperature=0.1
)

# Process nodes
results = await extractor.aextract(nodes)
```

Each extractor is designed to work asynchronously and handle batch processing efficiently, with built-in error handling and progress reporting.

To have a glimpse of what the metadata looks like, we can run the ingestion pipeline using the script in `src/scripts/metadata_structure.py`. We present and explain in details the ingestion pipeline in @sec-ingestion-pipeline. Then run the Python shiny app in `src/app/app-metadata.py` to visualize the metadata and structure of the documents. A demo is available on the [HF Space Demo for PDF Metadata](https://huggingface.co/spaces/nicolasb92/pdf-rag-metadata-demo).

![HF space demo for metadata and structure](figures/hf-demo-metadata.png){#fig-hf-demo-metadata fig-alt="HF space demo for metadata and structure"}

### Parsing Structure {#sec-parsing-structure}

#### Parsing Structures from Extracted Metadata {#sec-parsing-structures-extracted-metadata}

At the end of the extraction, we have two types of parsed structure. The portrait (report) structure and the landscape (presentation) structure. We will describe the differences between the two and their benefits.

**Portrait (Report) Structure**

``` markdown
# Deloitte. [line 0]
## Pushing through undercurrents [line 2]
### Technology's impact on systemic risk: A look at banking [line 3]
### Risk 1: Risk exposure from Banking as a Service offerings [line 15]
#### Table 1: Risk exposure from Banking as a Service offerings [line 29]
### Risk 2: Inadequate stability mechanisms for stablecoin arrangements [line 38]
#### Table 1: Information about forces that could amplify the risk and how the industry mitigate it? [line 52]
### Contacts [line 63]
```

-   Hierarchical Headers: Uses markdown heading levels (#, ##, ###, ####) to represent document hierarchy
-   Line Numbers: Each heading includes line numbers `[line X]` for precise content location
-   Linear Flow: Follows a traditional document structure with nested sections
-   Content Focus: Emphasizes content hierarchy and relationships
-   Example Use Case: Technical reports, research papers, documentation

**Landscape (Presentation) Structure**

``` markdown
# Everest Group® Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023
- Page 1 : Everest Group® Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023

# Introduction
- Page 2 : Introduction

# Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023
- Page 3 : Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023
- Page 4 : Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023
- Page 12 : Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023
- Page 13 : Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023

# Deloitte profile
- Page 5 : Deloitte profile (page 1 of 6)
- Page 6 : Deloitte profile (page 2 of 6)
- Page 7 : Deloitte profile (page 3 of 6)
- Page 8 : Deloitte profile (page 4 of 6)
- Page 9 : Deloitte profile (page 5 of 6)
- Page 10 : Deloitte profile (page 6 of 6)

# Appendix
- Page 11 : Appendix

# FAQs
- Page 14 : FAQs

# Everest Group®
- Page 15 : Everest Group®
```

-   Page-Based Organization: Groups content by pages under main sections
-   Explicit Page Numbers: Each entry shows "Page X : Title" format
-   Flat Section Hierarchy: Uses mainly top-level headings (#) for major sections
-   Sequential Listing: Lists pages sequentially within each section
-   Example Use Case: Slide decks, presentations, visual-heavy documents

Benefits

1.  **Document Navigation**
    -   Portrait: Quick access to specific content sections via line numbers
    -   Landscape: Easy location of specific slides via page numbers
2.  **Content Retrieval**
    -   Portrait: Granular access to nested content hierarchies
    -   Landscape: Efficient slide/page-based content lookup
3.  **Structure Preservation**
    -   Portrait: Maintains detailed document hierarchy and relationships
    -   Landscape: Preserves presentation flow and slide organization

Then, we can use File: `src/pdf_rag/structure_parsers.py` to parse this structure into a formal tree representation.

Here's a detailed description of both parsing functions:

`parse_portrait_structure`

This function parses the structure of portrait-formatted documents (like reports) and creates a tree representation.

-   Takes a `BaseNode` document as input
-   Creates a hierarchical tree structure based on document headers
-   Headers must follow format: `#{level} {title} [line {number}]`
-   Validates line numbers are in ascending order
-   Returns a `TreeNode` representing the document structure

`parse_landscape_structure`

This function parses the structure of landscape-formatted documents (like presentations) and creates a tree representation.

-   Takes a `BaseNode` document as input
-   Handles both section headers and page entries
-   Creates a hierarchical structure with page numbers
-   Tracks missing or duplicate pages
-   Creates an "Uncategorized" section for orphaned pages

Both functions return a `TreeNode` object that can be traversed using breadth-first search (bfs) and supports standard tree operations like adding/removing children and setting parents.

Here are the parsed structures for the portrait and landscape documents: You can also find them on the huggingface space demo for metadata and structure [HF Space Demo for PDF Metadata](https://huggingface.co/spaces/nicolasb92/pdf-rag-metadata-demo).

Indentation shows parent/child relationships For landscape-oriented content, Numbers in \[\] represent: Positive numbers: page numbers Negative numbers: abstract nodes grouping related sections

```         
life-sciences-smart-manufacturing-services-peak-matrix-assessment-2023 [-1]
  Everest Group® Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [-2]
    Everest Group® Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [1]
  Introduction [-3]
    Introduction [2]
  Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [-4]
    Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [3]
    Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [4]
    Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [12]
    Life Sciences Smart Manufacturing Services PEAK Matrix® Assessment 2023 [13]
  Deloitte profile [-5]
    Deloitte profile (page 1 of 6) [5]
    Deloitte profile (page 2 of 6) [6]
    Deloitte profile (page 3 of 6) [7]
    Deloitte profile (page 4 of 6) [8]
    Deloitte profile (page 5 of 6) [9]
    Deloitte profile (page 6 of 6) [10]
  Appendix [-6]
    Appendix [11]
  FAQs [-7]
    FAQs [14]
  Everest Group® [-8]
    Everest Group® [15]
```

For portrait-oriented content, Numbers in \[\] represent: Positive numbers: line numbers Negative numbers: abstract nodes grouping related sections

```         
deloitte-tech-risk-sector-banking [-1]
  Deloitte. [0]
    Pushing through undercurrents [2]
      Technology's impact on systemic risk: A look at banking [3]
      Risk 1: Risk exposure from Banking as a Service offerings [15]
        Table 1: Risk exposure from Banking as a Service offerings [29]
      Risk 2: Inadequate stability mechanisms for stablecoin arrangements [38]
        Table 1: Information about forces that could amplify the risk and how the industry mitigate it? [52]
      Contacts [63]
```

#### Tree Index {#sec-tree-index}

The final step is - to create a hierarchical index of the processed documents - to support two types of node parsing: - `MarkdownLineNodeParser`: For portrait-oriented content - `MarkdownPageNodeParser`: For landscape-oriented content - to optionally export to a Neo4j database

to create a hierarchical index of the processed documents. The `TreeIndex` class extends `BaseIndex` to provide a hierarchical tree-based indexing structure for document nodes. It's specifically designed to handle both portrait (reports) and landscape (presentations) document structures.

Note that the `TreeIndex` class is part of the LlamaIndex framework, which provides a flexible and extensible indexing system for document nodes. It supports various indexing structures, including tree-based, graph-based, and vector-based indexes, to suit different document types and use cases. It is worked in progress we provide a first draft of the tree Index but do not use it. The class is not yet fully implemented.

The `TreeIndex` class extends `BaseIndex` to provide a hierarchical tree-based indexing structure for document nodes. It's specifically designed to handle both portrait (reports) and landscape (presentations) formatted documents.

**1. Data Structure**

-   Uses `IndexStructTree` to maintain hierarchical relationships
-   Stores nodes in a tree structure with parent-child relationships
-   Supports both root-level and nested nodes
-   Maintains bidirectional references (parent-to-children and child-to-parent)

**2. Node Management**

-   Node insertion with automatic relationship building
-   Node deletion with relationship cleanup
-   Reference document tracking
-   Support for abstract nodes (section headers) and content nodes (pages)

**3. Neo4j Integration**

-   Export functionality to Neo4j graph database
-   Creates nodes and relationships in Neo4j
-   Maintains document structure and metadata
-   Supports constraints and cleanup operations

![Neo4j visualisation](figures/neo4j.png){#fig-neo4j-visualisation fig-alt="Neo4j visualisation"}

**Usage Example**

``` python
# Create index with nodes
index = TreeIndex(
    nodes=document_nodes,
    show_progress=True
)

# Export to Neo4j
config = Neo4jConfig(
    uri="neo4j://localhost:7687",
    username="neo4j",
    password="password",
    database="neo4j"
)
index.export_to_neo4j(config=config)
```

This implementation is particularly useful for maintaining document structure while enabling efficient traversal and querying of document hierarchies.

### Script and Ingestion pipeline {#sec-ingestion-pipeline}

File: `src/scripts/metadata_structure.py`

Let us now describe the ingestion pipeline to have a glimpse of what the metadata looks like.

The script in `src/scripts/metadata_structure.py` executes all the extractors in sequence through an ingestion pipeline. This process enriches documents with comprehensive metadata including author information, document context, table of contents, and structural relationships. The resulting metadata provides a rich foundation for document analysis and retrieval.

The Python script `src/scripts/metadata_structure.py` implements an extraction pipeline for processing PDF documents. It is designed to extract, transform, and index content from PDFs using various AI models (Gemini and Mistral) and store the processed data in both a local storage and optionally in a Neo4j database.

Configuration (`PipelineConfig`) - Handles configuration through a dataclass including: - Directory paths - API keys for Gemini and Mistral - Neo4j connection details - Pipeline execution options

The configuration file is in YAML format and includes settings for the pipeline, API keys, and file paths.

The pipeline first ingests the PDF documents using `PDFDirectoryReader` to read PDF files.

Then it processes the documents through the ingestion pipeline, which includes several transformations:

1.  `ReformatMarkdownComponent`: Reformats content to markdown
2.  `ContextExtractor`: Extracts contextual information
3.  `TableOfContentsExtractor`: Extracts table of contents
4.  `TableOfContentsCreator`: Creates structured TOC
5.  `LandscapePagesExtractor`: Handles landscape-oriented pages
6.  `StructureExtractor`: Extracts document structure

It stores the results in a `SimpleDocumentStore` for persistence and loading of processed data.

Tree Indexing

-   Creates a hierarchical index of the processed documents
-   Supports two types of node parsing:
    -   `MarkdownLineNodeParser`: For portrait-oriented content
    -   `MarkdownPageNodeParser`: For landscape-oriented content
-   Optional export to Neo4j database

**Usage**

``` bash
python scripts/metadata_structure.py --config path/to/config.yaml
```

-   `ingest`: Runs only the ingestion pipeline

-   `tree`: Creates the tree index

-   `all`: Runs both ingestion and indexing

-   Multi-worker processing support

-   Caching mechanism

-   Progress tracking

-   Persistent storage

-   Configuration validation

-   Environment variable support

-   Optional Neo4j integration

This script is particularly useful for organizations needing to process large collections of PDF documents and create searchable, structured knowledge bases from them.