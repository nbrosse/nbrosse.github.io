[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nicolas’ Notebook",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\nDescription\n\n\n\n\n\n\nFeb 26, 2025\n\n\nPython Concurrency\n\n\npython\n\n\nAn introduction to Python concurrency, covering core concepts, practical examples, and considerations for its use.\n\n\n\n\nFeb 18, 2025\n\n\nPDF Parsing for LLM Input\n\n\ndeep learning, LLM\n\n\nAn exploration of current PDF parsing capabilities for Large Language Model (LLM) input.\n\n\n\n\nFeb 6, 2025\n\n\nPredicting MHC-Peptide Binding with Machine Learning\n\n\ndeep learning, biology\n\n\nUsing machine learning to predict peptide binding affinity to Major Histocompatibility Complex (MHC) molecules.\n\n\n\n\nApr 24, 2024\n\n\nEncoding Distances in Molecules and Pockets: A Comparison of GBFPT and DCEPT\n\n\ndeep learning, biology\n\n\nA comparative analysis of Gaussian kernel with pair type (GBFPT) and Discretization categorical embedding with Pair Type (DCEPT) for encoding distances in 3D molecular representations, using the Uni-Mol framework.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html",
    "href": "posts/py-concurrency/py-concurrency.html",
    "title": "Python Concurrency",
    "section": "",
    "text": "This blog post is organized as follows:\nEach section builds on the previous ones to provide a comprehensive understanding of Python concurrency."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#what-is-concurrency",
    "href": "posts/py-concurrency/py-concurrency.html#what-is-concurrency",
    "title": "Python Concurrency",
    "section": "What Is Concurrency?",
    "text": "What Is Concurrency?\nConcurrency is the simultaneous occurrence of events. In Python, these events are called:\n\nThread\nTask\nProcess\n\nThese all represent a sequence of instructions that run in order. They can be stopped, and the CPU can switch to a different one. The state of each sequence is saved so it can be restored.\nThreads, tasks, and processes differ in their details. Multiple system processes can enable Python to run these sequences at the same time.\nThreads and asynchronous tasks run on a single processor, meaning they run one at a time. They take turns to speed up the overall process.\nIn a multi-threaded approach, the operating system knows about each thread and can interrupt it to run a different thread. This is also true for processes and is called preemptive multitasking.\nIn preemptive multitasking, code in the thread doesn’t need to do anything special to make the switch. A context switch can happen in the middle of a Python statement. This is because Python statements consist of low-level bytecode instructions.\nAsynchronous tasks use cooperative multitasking. The tasks cooperate by announcing when they’re ready to be switched out. The code in the task has to change to make this happen.\nThe benefit is that you know where your task will be swapped out, making it easier to understand the flow of execution. A task won’t be swapped out in the middle of a Python statement unless that statement is appropriately marked."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#what-is-parallelism",
    "href": "posts/py-concurrency/py-concurrency.html#what-is-parallelism",
    "title": "Python Concurrency",
    "section": "What Is Parallelism?",
    "text": "What Is Parallelism?\nParallelism involves executing separate processes, each running in its own Python interpreter.\nEach process can run on a different CPU core. This means they can run at the same time.\nHere’s a summary of Python modules for concurrency and parallelism:\n\n\n\n\n\n\n\n\n\nPython Module\nCPU\nMultitasking\nSwitching Decision\n\n\n\n\nasyncio\nOne\nCooperative\nThe tasks decide when to give up control.\n\n\nthreading\nOne\nPreemptive\nThe operating system decides when to switch tasks external to Python.\n\n\nmultiprocessing\nMany\nPreemptive\nThe processes all run at the same time on different processors.\n\n\n\nThese modules will be explored in this blog post.\nthreading and multiprocessing are low-level building blocks. They can often be replaced with concurrent.futures, which provides a higher-level interface. asyncio offers a different approach to concurrency.\nEach type of concurrency can be useful in its own way."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#synchronous-version",
    "href": "posts/py-concurrency/py-concurrency.html#synchronous-version",
    "title": "Python Concurrency",
    "section": "Synchronous Version",
    "text": "Synchronous Version\nThis version doesn’t use concurrency:\n\n\n\nListing 1: io_non_concurrent.py\n\n\nimport time\n\nimport requests\n\ndef main():\n    sites = [\n        \"https://www.jython.org\",\n        \"http://olympus.realpython.org/dice\",\n    ] * 80\n    start_time = time.perf_counter()\n    download_all_sites(sites)\n    duration = time.perf_counter() - start_time\n    print(f\"Downloaded {len(sites)} sites in {duration} seconds\")\n\ndef download_all_sites(sites):\n    with requests.Session() as session:\n        for url in sites:\n            download_site(url, session)\n\ndef download_site(url, session):\n    with session.get(url) as response:\n        print(f\"Read {len(response.content)} bytes from {url}\")\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nThis program downloads site contents from a list of addresses and prints their sizes. A session object from requests is used. Creating a Session object allows the library to retain state across requests and reuse the connection to speed things up. The session is created in download_all_sites() and then the list of sites is iterated through, downloading each one. Finally, the execution time is printed. Here’s an example of the final output:\n$ python io_non_concurrent.py\nRead 10966 from https://www.jython.org\nRead 276 from http://olympus.realpython.org/dice\n ⋮\nDownloaded 160 sites in 14.289619207382202 seconds\nThese results may vary depending on network conditions."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#multi-threaded-version",
    "href": "posts/py-concurrency/py-concurrency.html#multi-threaded-version",
    "title": "Python Concurrency",
    "section": "Multi-Threaded Version",
    "text": "Multi-Threaded Version\nWriting a multi-threaded program takes more effort. Here’s the same program using concurrent.futures and threading:\n\n\n\nListing 2: io_threads.py\n\n\nimport threading\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nimport requests\n\nthread_local = threading.local()\n\ndef main():\n    sites = [\n        \"https://www.jython.org\",\n        \"http://olympus.realpython.org/dice\",\n    ] * 80\n    start_time = time.perf_counter()\n    download_all_sites(sites)\n    duration = time.perf_counter() - start_time\n    print(f\"Downloaded {len(sites)} sites in {duration} seconds\")\n\ndef download_all_sites(sites):\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        executor.map(download_site, sites)\n\ndef download_site(url):\n    session = get_session_for_thread()\n    with session.get(url) as response:\n        print(f\"Read {len(response.content)} bytes from {url}\")\n\ndef get_session_for_thread():\n    if not hasattr(thread_local, \"session\"):\n        thread_local.session = requests.Session()\n    return thread_local.session\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nThe overall structure is the same.\nA ThreadPoolExecutor is created to manage the threads. In this case, five workers or threads are requested. The correct number of threads is not constant from one task to another. With IO-bound problems, you’re not limited to the number of CPU cores. However, at some point, diminishing returns will occur due to the overhead of switching threads. Experimentation is recommended. A ThreadPoolExecutor creates a pool of threads, each of which can run concurrently. The executor controls how and when each of the threads in the pool will run. Using a thread pool can be beneficial when you have limited system resources but still want to handle many tasks.\nIn this version, the executor calls download_site() instead of doing it manually in a loop. The executor.map() method distributes the workload across the available threads. This method takes:\n\nA function to be executed on each data item\nA collection of data items to be processed by that function\n\nSince the function passed to .map() must take one argument, download_site() was modified to only accept a URL.\nBecause the operating system controls when tasks get interrupted, any data shared between the threads needs to be thread-safe. requests.Session() isn’t thread-safe.\nOne strategy is to use a thread-safe data structure. Another strategy is to use thread-local storage. When threading.local() is called, an object that resembles a global variable but is specific to each individual thread is created.\nWhen get_session_for_thread() is called, the session it looks up is specific to the particular thread on which it’s running. So each thread will create a session the first time it calls get_session_for_thread() and then will use that session on each subsequent call.\nHere’s the output:\n$ python io_threads.py\nRead 10966 from https://www.jython.org\nRead 276 from http://olympus.realpython.org/dice\n ⋮\nDownloaded 160 sites in 3.190047219999542 seconds\nThis is faster than the non-concurrent version.\nHere’s the execution timing diagram:\n\n\n\nTiming Diagram of a Threading Solution\n\n\nThe program uses multiple threads to have many open requests out to web sites at the same time. It takes more code to make this happen, and you have to give some thought to what data is shared between threads. Threads can interact in ways that are subtle and hard to detect. These interactions can cause race conditions that frequently result in random, intermittent bugs that can be difficult to find."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#asynchronous-version",
    "href": "posts/py-concurrency/py-concurrency.html#asynchronous-version",
    "title": "Python Concurrency",
    "section": "Asynchronous Version",
    "text": "Asynchronous Version\nUsing multithreading can cut down the total execution time. Python’s asyncio module enables asynchronous I/O and can be even faster.\nAsynchronous processing is a concurrency model that’s suited for I/O-bound tasks. It avoids the overhead of context switching between threads by employing the event loop, non-blocking operations, and coroutines. Asynchronous code needs only one thread of execution to run concurrently.\nThe event loop controls how and when each asynchronous task gets to execute. It continuously loops through your tasks while monitoring their state. When the current task starts waiting for an I/O operation to finish, the loop suspends it and switches to another task. When the expected event occurs, the loop resumes the suspended task in the next iteration.\nA coroutine is similar to a thread but more lightweight. You can spawn many more coroutines than threads without significant overhead.\nBlocking function calls aren’t allowed in coroutines. A blocking call prevents other code from running while it’s waiting for data to arrive. A non-blocking call can give up control and wait to be notified when the data is ready.\nIn Python, you create a coroutine object by calling an asynchronous function, also known as a coroutine function. These are defined with the async def statement. Only within the body of an asynchronous function can you use the await keyword, which pauses the execution of the coroutine until the awaited task is completed:\nimport asyncio\n\nasync def main():\n    await asyncio.sleep(3.5)\nIn this case, main() is defined as an asynchronous function. The await keyword makes a non-blocking call to asyncio.sleep(), simulating a delay. While main() awaits the wake-up event, other tasks could potentially run.\nNote: To run the sample code above, you’ll need to either wrap the call to main() in asyncio.run() or await main() in Python’s asyncio REPL.\nThe Requests library is blocking, so a non-blocking counterpart, such as aiohttp, is needed. After installing this library, you can use it in the asynchronous version of the code:\n\n\n\nListing 3: io_asyncio.py\n\n\nimport asyncio\nimport time\nimport aiohttp\n\nasync def main():\n    sites = [\n        \"https://www.jython.org\",\n        \"http://olympus.realpython.org/dice\",\n    ] * 80\n    start_time = time.perf_counter()\n    await download_all_sites(sites)\n    duration = time.perf_counter() - start_time\n    print(f\"Downloaded {len(sites)} sites in {duration} seconds\")\n\nasync def download_all_sites(sites):\n    async with aiohttp.ClientSession() as session:\n        tasks = [download_site(url, session) for url in sites]\n        await asyncio.gather(*tasks, return_exceptions=True)\n\nasync def download_site(url, session):\n    async with session.get(url) as response:\n        print(f\"Read {len(await response.read())} bytes from {url}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n\nThis version looks similar to the synchronous one.\nHere are the main differences:\n\nasyncio is imported from Python’s standard library.\nThe aiohttp library is imported.\nFunctions are redefined as asynchronous ones with the async keyword.\nThe await keyword is prepended to download_all_sites().\nThe async with statement is leveraged to create asynchronous context managers.\nA list of tasks is created using a list comprehension.\nasyncio.gather() is used to run all the tasks concurrently.\nThe completion of the session’s HTTP GET request is awaited before printing.\n\nThe session is shared across all tasks because they’re all running on the same thread.\nOne of the advantages of asyncio is that it scales well. Each task takes fewer resources and less time to create than a thread.\nThe asynchronous version is the fastest:\n$ python io_asyncio.py\nRead 10966 bytes from https://www.jython.org\nRead 10966 bytes from https://www.jython.org\n ⋮\nDownloaded 160 sites in 0.49083488899850636 seconds\nHere’s the execution timing diagram:\n\n\n\nTiming Diagram of a Asyncio Solution\n\n\nAdding async and await can be a complication, but it forces you to think about when a given task will get swapped out. The asyncio example can be run with hundreds of tasks without slowing it down. You need special asynchronous versions of libraries to gain the full advantage of asyncio. If one of the tasks doesn’t cooperate, then all the advantages of cooperative multitasking get thrown away. See Section 4 for a deep dive into asynchronous I/O with AsyncIOs"
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#process-based-version",
    "href": "posts/py-concurrency/py-concurrency.html#process-based-version",
    "title": "Python Concurrency",
    "section": "Process-Based Version",
    "text": "Process-Based Version\nThe examples so far have run on a single CPU. The multiprocessing module was designed to break down that barrier and run your code across multiple CPUs. It does this by creating a new instance of the Python interpreter to run on each CPU. Bringing up a separate Python interpreter is a heavyweight operation. Unlike the previous approaches, using multiprocessing allows you to take full advantage of the all CPUs that your computer has. Here’s the sample code:\n\n\n\nListing 4: io_processes.py\n\n\nimport atexit\nimport multiprocessing\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\nimport requests\n\nsession: requests.Session\n\ndef main():\n    sites = [\n        \"https://www.jython.org\",\n        \"http://olympus.realpython.org/dice\",\n    ] * 80\n    start_time = time.perf_counter()\n    download_all_sites(sites)\n    duration = time.perf_counter() - start_time\n    print(f\"Downloaded {len(sites)} sites in {duration} seconds\")\n\ndef download_all_sites(sites):\n    with ProcessPoolExecutor(initializer=init_process) as executor:\n        executor.map(download_site, sites)\n\ndef download_site(url):\n    with session.get(url) as response:\n        name = multiprocessing.current_process().name\n        print(f\"{name}:Read {len(response.content)} bytes from {url}\")\n\ndef init_process():\n    global session\n    session = requests.Session()\n    atexit.register(session.close)\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nThis looks similar to the multi-threaded example.\nHere’s what this code does:\n\nA global variable is declared to hold the session object.\nThreadPoolExecutor is replaced with ProcessPoolExecutor from concurrent.futures and init_process() is passed.\nA custom initializer function is defined that each process will call shortly after starting.\nA cleanup function is registered with atexit.\n\nThe pool creates a number of separate Python interpreter processes. The communication between the main process and the other processes is handled. The pool instance doesn’t specify how many processes to create. By default, it’ll determine the number of CPUs and match that. For an I/O-bound problem, increasing the number of processes won’t make things faster.\nNote: If you need to exchange data between your processes, then it requires expensive inter-process communication (IPC) and data serialization.\nEach process in the pool has its own memory space. They can’t easily share things like a session object. The initializer function parameter is built for this case. A global session variable can be initialized to hold the single session for each process.\nHere’s the output:\n$ python io_processes.py\nForkProcess-3:Read 10966 bytes from https://www.jython.org\nForkProcess-4:Read 276 bytes from http://olympus.realpython.org/dice\n ⋮\nDownloaded 160 sites in 3.428215079999063 seconds\nOn a computer with four CPU cores, it runs about four times faster than the synchronous version. It’s slower than the multi-threaded version and much slower than the asynchronous version.\nThe execution timing diagram for this code looks like this:\n\n\n\nTiming Diagram of a Multiprocessing Solution\n\n\nThere are separate processes executing in parallel. The diagrams of each one resemble the non-concurrent version. Multiprocessing is more useful for CPU-bound examples."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#async-and-await-keywords",
    "href": "posts/py-concurrency/py-concurrency.html#async-and-await-keywords",
    "title": "Python Concurrency",
    "section": "async and await Keywords",
    "text": "async and await Keywords\nThe async and await keywords are fundamental to asyncio.\n\nasync def: Defines a coroutine, a function that can be suspended and resumed.\nawait: Pauses execution inside a coroutine until an awaitable object (another coroutine or a Future) completes. When a coroutine encounters await, it yields control back to the event loop.\n\nasync def f(x):\n    y = await z(x)  # OK - `await` and `return` allowed in coroutines\n    return y\n\nasync def g(x):\n    yield x  # OK - this is an async generator\nA function defined with async def is a coroutine. It may use await, return, or yield, but all are optional.\nUsing await and/or return creates a coroutine function. To call a coroutine function, you must await it to get its results. It is less common to use yield in an async def block. This creates an asynchronous generator, iterated over with async for. Anything defined with async def may not use yield from, which will raise a SyntaxError.\nExample:\nimport asyncio\n\nasync def my_coroutine():\n    print(\"Coroutine started\")\n    await asyncio.sleep(1)  # Simulate an I/O operation\n    print(\"Coroutine finished\")\n\nasync def main():\n    await my_coroutine()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\nThis code demonstrates:\n\nmy_coroutine is defined as an async function, making it a coroutine.\nawait asyncio.sleep(1) pauses the coroutine for 1 second, simulating an I/O operation. The event loop can schedule other coroutines.\nasyncio.run(main()) starts the event loop and runs the main coroutine."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#asynchronous-vs.-synchronous-execution-in-python-a-comparison",
    "href": "posts/py-concurrency/py-concurrency.html#asynchronous-vs.-synchronous-execution-in-python-a-comparison",
    "title": "Python Concurrency",
    "section": "Asynchronous vs. Synchronous Execution in Python: A Comparison",
    "text": "Asynchronous vs. Synchronous Execution in Python: A Comparison\nThis section compares the execution time of asynchronous and synchronous code in Python using a simple example. The example consists of a count function that prints “One”, waits for 1 second, and then prints “Two”. We execute this function three times, once using asyncio for asynchronous execution and once using a simple for loop for synchronous execution.\nAsynchronous Example\n\n\n\nListing 5: countasync.py\n\n\nimport asyncio\nimport time\n\nasync def count():\n    print(\"One\")\n    await asyncio.sleep(1)\n    print(\"Two\")\n\nasync def main():\n    await asyncio.gather(count(), count(), count())\n\nif __name__ == \"__main__\":\n    s = time.perf_counter()\n    asyncio.run(main())\n    elapsed = time.perf_counter() - s\n    print(f\"{__file__} executed in {elapsed:0.2f} seconds.\")\n\n\n\nExplanation:\n\nasync def count(): defines an asynchronous function. The await asyncio.sleep(1) line allows the event loop to switch to other tasks while waiting for the sleep to complete, enabling concurrency.\nasync def main(): defines another asynchronous function that uses asyncio.gather() to run three instances of count() concurrently. asyncio.gather() ensures that all provided awaitables complete before it returns.\nasyncio.run(main()) starts the asyncio event loop and runs the main() function.\n\nOutput:\n$ python countasync.py\nOne\nOne\nOne\nTwo\nTwo\nTwo\ncountasync.py executed in 1.01 seconds.\nAs observed, the execution time is approximately 1 second. This is because all three count() functions are executed concurrently. The asyncio.sleep(1) calls allow the event loop to switch between the functions, effectively overlapping the wait times. The small amount over 1 second likely represents overhead from the asyncio event loop and the print function.\nSynchronous Example\n\n\n\nListing 6: countsync.py\n\n\nimport time\n\ndef count():\n    print(\"One\")\n    time.sleep(1)\n    print(\"Two\")\n\ndef main():\n    for _ in range(3):\n        count()\n\nif __name__ == \"__main__\":\n    s = time.perf_counter()\n    main()\n    elapsed = time.perf_counter() - s\n    print(f\"{__file__} executed in {elapsed:0.2f} seconds.\")\n\n\n\nExplanation:\n\ndef count(): defines a regular synchronous function.\ntime.sleep(1) pauses the execution of the current thread for 1 second. No other code can execute during this time.\ndef main(): calls the count() function three times in a loop. Each call blocks until it completes.\n\nOutput:\n$ python3 countsync.py\nOne\nTwo\nOne\nTwo\nOne\nTwo\ncountsync.py executed in 3.01 seconds.\nAs observed, the execution time is approximately 3 seconds. This is because each count() function call takes 1 second of sleep time, and the functions are executed sequentially."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#components-of-asyncio",
    "href": "posts/py-concurrency/py-concurrency.html#components-of-asyncio",
    "title": "Python Concurrency",
    "section": "Components of asyncio",
    "text": "Components of asyncio\n\nEvent Loop: Manages coroutine execution and I/O events. asyncio.run() creates and manages it.\nCoroutines: Functions defined with async def that can be suspended and resumed.\nTasks: Represent a coroutine scheduled to run in the event loop, created using asyncio.create_task(). Tasks are essential for running coroutines concurrently.\nFutures: Represent the result of an asynchronous operation. Coroutines may await Futures, allowing them to wait for the completion of an asynchronous operation without blocking the entire program.\nQueues: asyncio provides queue classes (asyncio.Queue) similar to the standard queue.Queue but designed for asynchronous use. Queues are useful for coordinating communication between coroutines.\n\nThe Event Loop\nThe event loop monitors coroutines, identifies idle coroutines, and schedules executable tasks. It wakes up idle coroutines when their awaited resources become available.\nasyncio.run() manages the event loop implicitly:\nasyncio.run() obtains the event loop, runs tasks until completion, and then closes the loop.\nKey points about the event loop:\n\nCoroutines require the event loop to execute.\nBy default, an AsyncIO event loop runs in a single thread and on a single CPU core, which is often sufficient.\n\nThere’s a more long-winded way of managing the asyncio event loop, with get_event_loop(). The typical pattern looks like this and is taken from llama-index async_utils.py.\n\n\n\nListing 7: asyncio_run\n\n\ndef asyncio_run(coro: Coroutine) -&gt; Any:\n    \"\"\"Gets an existing event loop to run the coroutine.\n\n    If there is no existing event loop, creates a new one.\n    \"\"\"\n    try:\n        # Check if there's an existing event loop\n        loop = asyncio.get_event_loop()\n\n        # If we're here, there's an existing loop but it's not running\n        return loop.run_until_complete(coro)\n\n    except RuntimeError as e:\n        # If we can't get the event loop, we're likely in a different thread, or its already running\n        # asyncio.get_event_loop() raises RuntimeError if there's no running loop in the current thread.\n        try:\n            # If the first attempt failed, try creating and running a new event loop.\n            return asyncio.run(coro)  # asyncio.run() creates a new event loop, runs the coroutine, and closes the loop.\n        except RuntimeError as e:\n            # If asyncio.run() also raises RuntimeError, it likely means there's a nested asyncio call.\n            raise RuntimeError(\n                \"Detected nested async. Please use nest_asyncio.apply() to allow nested event loops.\"\n                \"Or, use async entry methods like `aquery()`, `aretriever`, `achat`, etc.\"\n            )\n\n\n\nThis function aims to run an asyncio coroutine. It first tries to get the current event loop. If one exists and is not running, it runs the coroutine in that loop. If getting the current loop fails (RuntimeError), it means there’s no running loop in the current thread. In that case, it tries to create a new loop using asyncio.run(). If creating a new loop also fails (another RuntimeError), it likely indicates a nested asyncio scenario (trying to run asyncio code within already running asyncio code). The error suggests using nest_asyncio or asynchronous alternatives to avoid nested loops. Nesting is generally discouraged in asyncio. nest_asyncio allows nesting, but it can lead to unexpected behavior. It is generally recommended to re-factor code that uses nested async calls."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#asyncio-examples-in-practice",
    "href": "posts/py-concurrency/py-concurrency.html#asyncio-examples-in-practice",
    "title": "Python Concurrency",
    "section": "AsyncIO Examples in Practice",
    "text": "AsyncIO Examples in Practice\n\nChained Coroutines\n\n\n\nListing 8: chained.py\n\n\nimport asyncio\nimport random\nimport time\n\nasync def part1(n: int) -&gt; str:\n    i = random.randint(0, 10)\n    print(f\"part1({n}) sleeping for {i} seconds.\")\n    await asyncio.sleep(i)\n    result = f\"result{n}-1\"\n    print(f\"Returning part1({n}) == {result}.\")\n    return result\n\nasync def part2(n: int, arg: str) -&gt; str:\n    i = random.randint(0, 10)\n    print(f\"part2{n, arg} sleeping for {i} seconds.\")\n    await asyncio.sleep(i)\n    result = f\"result{n}-2 derived from {arg}\"\n    print(f\"Returning part2{n, arg} == {result}.\")\n    return result\n\nasync def chain(n: int) -&gt; None:\n    start = time.perf_counter()\n    p1 = await part1(n)\n    p2 = await part2(n, p1)\n    end = time.perf_counter() - start\n    print(f\"--&gt;Chained result{n} =&gt; {p2} (took {end:0.2f} seconds).\")\n\nasync def main(*args):\n    await asyncio.gather(*(chain(n) for n in args))\n\nif __name__ == \"__main__\":\n    import sys\n    random.seed(444)\n    args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:])\n    start = time.perf_counter()\n    asyncio.run(main(*args))\n    end = time.perf_counter() - start\n    print(f\"Program finished in {end:0.2f} seconds.\")\n\n\n\nExample output:\n$ python3 chained.py 9 6 3\npart1(9) sleeping for 4 seconds.\npart1(6) sleeping for 4 seconds.\npart1(3) sleeping for 0 seconds.\nReturning part1(3) == result3-1.\npart2(3, 'result3-1') sleeping for 4 seconds.\nReturning part1(9) == result9-1.\npart2(9, 'result9-1') sleeping for 7 seconds.\nReturning part1(6) == result6-1.\npart2(6, 'result6-1') sleeping for 4 seconds.\nReturning part2(3, 'result3-1') == result3-2 derived from result3-1.\n--&gt;Chained result3 =&gt; result3-2 derived from result3-1 (took 4.00 seconds).\nReturning part2(6, 'result6-1') == result6-2 derived from result6-1.\n--&gt;Chained result6 =&gt; result6-2 derived from result6-1 (took 8.01 seconds).\nReturning part2(9, 'result9-1') == result9-2 derived from result9-1.\n--&gt;Chained result9 =&gt; result9-2 derived from result9-1 (took 11.01 seconds).\nProgram finished in 11.01 seconds.\npart1() sleeps for a variable time, and part2() starts as results become available. This example demonstrates how asyncio.gather can run multiple coroutines concurrently, and how await ensures that the second coroutine in each chain only runs after the first has completed. Each chain function represents an independent, sequential process. The final result showcases the execution time of individual chains and the total program execution time. Note that the total program time is roughly the longest individual chain time, demonstrating concurrency.\n\n\nProducer/Consumer Pattern with asyncio.Queue\n\n\n\nListing 9: asyncq.py\n\n\nimport asyncio\nimport itertools as it\nimport os\nimport random\nimport time\n\nasync def makeitem(size: int = 5) -&gt; str:\n    return os.urandom(size).hex()\n\nasync def randsleep(caller=None) -&gt; None:\n    i = random.randint(0, 10)\n    if caller:\n        print(f\"{caller} sleeping for {i} seconds.\")\n    await asyncio.sleep(i)\n\nasync def produce(name: int, q: asyncio.Queue) -&gt; None:\n    n = random.randint(0, 10)\n    for _ in it.repeat(None, n):  # Synchronous loop for each single producer\n        await randsleep(caller=f\"Producer {name}\")\n        i = await makeitem()\n        t = time.perf_counter()\n        await q.put((i, t))\n        print(f\"Producer {name} added &lt;{i}&gt; to queue.\")\n\nasync def consume(name: int, q: asyncio.Queue) -&gt; None:\n    while True:\n        await randsleep(caller=f\"Consumer {name}\")\n        i, t = await q.get()\n        now = time.perf_counter()\n        print(f\"Consumer {name} got element &lt;{i}&gt;\"\n              f\" in {now-t:0.5f} seconds.\")\n        q.task_done()\n\nasync def main(nprod: int, ncon: int):\n    q = asyncio.Queue()\n    producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)]\n    consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)]\n    await asyncio.gather(*producers)\n    await q.join()  # Implicitly awaits consumers, too\n    for c in consumers:\n        c.cancel()\n\nif __name__ == \"__main__\":\n    import argparse\n    random.seed(444)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--nprod\", type=int, default=5)\n    parser.add_argument(\"-c\", \"--ncon\", type=int, default=10)\n    ns = parser.parse_args()\n    start = time.perf_counter()\n    asyncio.run(main(**ns.__dict__))\n    elapsed = time.perf_counter() - start\n    print(f\"Program completed in {elapsed:0.5f} seconds.\")\n\n\n\nOutput\n$ python3 asyncq.py -p 2 -c 2\nProducer 0 sleeping for 2 seconds.\nProducer 1 sleeping for 2 seconds.\nConsumer 0 sleeping for 2 seconds.\nConsumer 1 sleeping for 4 seconds.\nProducer 0 added &lt;50679576b9&gt; to queue.\nProducer 0 sleeping for 3 seconds.\nProducer 1 added &lt;413dd61b37&gt; to queue.\nConsumer 0 got element &lt;50679576b9&gt; in 0.00015 seconds.\nConsumer 0 sleeping for 1 seconds.\nProducer 1 added &lt;1b64e8bb2f&gt; to queue.\nConsumer 1 got element &lt;413dd61b37&gt; in 0.00012 seconds.\nConsumer 1 sleeping for 5 seconds.\nProducer 1 added &lt;413dd61b37&gt; to queue.\nConsumer 0 got element &lt;1b64e8bb2f&gt; in 0.00009 seconds.\nConsumer 0 sleeping for 5 seconds.\nProgram completed in 7.02420 seconds.\nThis example illustrates the producer-consumer pattern using asyncio.Queue. Multiple producers generate random items and place them in the queue, while multiple consumers retrieve items from the queue and process them. asyncio.Queue handles synchronization between producers and consumers, ensuring that consumers don’t try to retrieve items from an empty queue and that producers don’t overwhelm the consumers. The q.join() method ensures that the main function waits until all items in the queue have been processed before canceling the consumers and exiting. The producers are stopped when they are finished producing items, while the consumers are stopped after the queue is emptied, preventing an infinite loop. The time elapsed between item production and consumption is measured, demonstrating the efficiency of the asynchronous queue in handling concurrent operations.\n\n\nSome Utility Functions from Llama-Index for Handling Asynchronous Tasks\nThis section presents three utility functions from the llama-index library that help manage asynchronous tasks in different ways:\n\nA function to execute a list of async tasks (with optional progress bar)\nA function to run tasks in batches to avoid memory issues\nA function to run tasks with a limited number of workers\n\nThese functions build on the core asyncio concepts covered earlier and provide practical solutions for common async programming needs.\n\n\n\nListing 10: llamaindex_async_utils.py\n\n\ndef run_async_tasks(\n    tasks: List[Coroutine],\n    show_progress: bool = False,\n    progress_bar_desc: str = \"Running async tasks\",\n) -&gt; List[Any]:\n    \"\"\"Run a list of async tasks.\"\"\"\n    tasks_to_execute: List[Any] = tasks\n    if show_progress:\n        try:\n            import nest_asyncio\n            from tqdm.asyncio import tqdm\n\n            # jupyter notebooks already have an event loop running\n            # we need to reuse it instead of creating a new one\n            nest_asyncio.apply()\n            loop = asyncio.get_event_loop()\n\n            async def _tqdm_gather() -&gt; List[Any]:\n                return await tqdm.gather(*tasks_to_execute, desc=progress_bar_desc)\n\n            tqdm_outputs: List[Any] = loop.run_until_complete(_tqdm_gather())\n            return tqdm_outputs\n        # run the operation w/o tqdm on hitting a fatal\n        # may occur in some environments where tqdm.asyncio\n        # is not supported\n        except Exception:\n            pass\n\n    async def _gather() -&gt; List[Any]:\n        return await asyncio.gather(*tasks_to_execute)\n\n    outputs: List[Any] = asyncio_run(_gather())\n    return outputs\n\n\n\nThis function runs a list of asynchronous tasks concurrently using asyncio.gather().\n\nIt takes a list of coroutines (tasks), a boolean to show progress, and an optional progress bar description.\nIf show_progress is True, it attempts to use tqdm.asyncio to display a progress bar.\n\nIt uses nest_asyncio.apply() to handle cases where the code is running in an environment like Jupyter notebooks, which already have an event loop.\nIt defines an inner coroutine _tqdm_gather() that uses tqdm.gather() to run the tasks and display the progress.\nIt runs _tqdm_gather() using asyncio_run().\nIf any exception occurs during the tqdm process (e.g., tqdm.asyncio is not supported), it falls back to running the tasks without a progress bar.\n\nIf show_progress is False or the tqdm process fails, it defines an inner coroutine _gather() that uses asyncio.gather() to run the tasks concurrently.\nIt runs _gather() using asyncio_run().\nIt returns a list of the results from the completed tasks.\n\n\n\n\nListing 11: llamaindex_async_utils.py\n\n\ndef chunks(iterable: Iterable, size: int) -&gt; Iterable:\n    args = [iter(iterable)] * size\n    return zip_longest(*args, fillvalue=None)\n\nasync def batch_gather(\n    tasks: List[Coroutine], batch_size: int = 10, verbose: bool = False\n) -&gt; List[Any]:\n    output: List[Any] = []\n    for task_chunk in chunks(tasks, batch_size):\n        task_chunk = (task for task in task_chunk if task is not None)\n        output_chunk = await asyncio.gather(*task_chunk)\n        output.extend(output_chunk)\n        if verbose:\n            print(f\"Completed {len(output)} out of {len(tasks)} tasks\")\n    return output\n\n\n\nThe function chunks splits an iterable into chunks of a specified size.\n\nIt takes an iterable and the desired chunk size as input.\nIt creates multiple iterators from the input iterable using [iter(iterable)] * size.\nIt uses zip_longest() to group elements from these iterators into tuples, effectively creating the chunks.\nThe fillvalue=None argument ensures that shorter chunks are padded with None if the input iterable is not evenly divisible by the chunk size.\nThe function returns an iterator that yields the chunks. For example, chunks([1, 2, 3, 4, 5, 6, 7], 3) will return [(1, 2, 3), (4, 5, 6), (7, None, None)]\n\nThe function batch_gather runs a list of asynchronous tasks in batches.\n\nIt takes a list of coroutines (tasks), a batch size, and a boolean for verbose output.\nIt uses the chunks() function to split the tasks into batches.\nFor each batch (task_chunk), it filters out any None values (which might have been added by chunks() due to padding).\nIt uses asyncio.gather() to run the tasks in the current batch concurrently.\nThe results from each batch are added to the output list.\nIf verbose is True, it prints a message indicating how many tasks have been completed so far.\nThe function returns a list of the results from all the completed tasks. This is useful when you have a very large list of coroutines, as sending them all to asyncio.gather could result in memory errors.\n\n\n\n\nListing 12: llamaindex_async_utils.py\n\n\nasync def run_jobs(\n    jobs: List[Coroutine[Any, Any, T]],\n    show_progress: bool = False,\n    workers: int = DEFAULT_NUM_WORKERS,\n    desc: Optional[str] = None,\n) -&gt; List[T]:\n    \"\"\"Run jobs.\n\n    Args:\n        jobs (List[Coroutine]):\n            List of jobs to run.\n        show_progress (bool):\n            Whether to show progress bar.\n\n    Returns:\n        List[Any]:\n            List of results.\n    \"\"\"\n    semaphore = asyncio.Semaphore(workers)\n\n    async def worker(job: Coroutine) -&gt; Any:\n        async with semaphore:\n            return await job\n\n    pool_jobs = [worker(job) for job in jobs]\n\n    if show_progress:\n        from tqdm.asyncio import tqdm_asyncio\n        results = await tqdm_asyncio.gather(*pool_jobs, desc=desc)\n    else:\n        results = await asyncio.gather(*pool_jobs)\n\n    return results\n\n\n\nThis function runs a list of asynchronous jobs (coroutines) with a specified number of workers and optional progress tracking.\n\nIt uses a semaphore to limit the number of concurrent workers.\nIt defines an inner coroutine worker() that acquires the semaphore before running a job and releases it afterward, ensuring that only a limited number of jobs run concurrently.\nIt creates a list of worker tasks (pool_jobs) by mapping each job to the worker() coroutine.\nIf show_progress is True, it uses tqdm_asyncio.gather() to run the worker tasks and display a progress bar.\nIf show_progress is False, it uses asyncio.gather() to run the worker tasks concurrently without a progress bar.\nThe function returns a list of the results from the completed jobs. This is useful when you want to limit the number of concurrent asyncio tasks being run, perhaps because of rate limiting by an API, or resource constraints on your system."
  },
  {
    "objectID": "posts/py-concurrency/py-concurrency.html#considerations-for-using-asyncio",
    "href": "posts/py-concurrency/py-concurrency.html#considerations-for-using-asyncio",
    "title": "Python Concurrency",
    "section": "Considerations for Using asyncio",
    "text": "Considerations for Using asyncio\nasyncio is suitable for I/O-bound tasks:\n\nNetwork applications: web servers, chat applications, API clients.\nWeb scraping: fetching data from multiple websites concurrently.\nReal-time applications: handling asynchronous events and data streams.\n\nIt is not appropriate for CPU-bound tasks like complex calculations or image processing. For CPU-bound tasks, consider multiprocessing.\nAdvantages of asyncio\n\nEfficiency: Reduces blocking and increases resource utilization.\nScalability: Handles concurrent connections with limited overhead.\nConcurrency with a single thread: Reduces multithreading complexities."
  },
  {
    "objectID": "posts/pdf-parsing/pdf-parsing.html",
    "href": "posts/pdf-parsing/pdf-parsing.html",
    "title": "PDF Parsing for LLM Input",
    "section": "",
    "text": "This blog post explores the current landscape of PDF parsing for use as input to Large Language Models (LLMs). Extracting meaningful information from PDFs can be challenging due to their complex structure. This article examines several approaches, their strengths, and limitations, with a focus on their suitability for LLM integration (markdown output).\nWe begin with a detailed presentation of some open-source PDF parsing libraries: Docling, Marker-PDF, and MinerU in Section 1. In particular, we provide a comprehensive overview of the Docling pipeline, a modular and open-source PDF processing pipeline designed to transform PDFs into a structured representation (the DoclingDocument) in Section 1.1. We also discuss Marker-PDF and MinerU in Section 1.2 and Section 1.3. The objective is to gain an understanding of how modern PDF parsing libraries function, in particular the role of deep learning models in PDF parsing and extraction, focusing on layout analysis, table structure recognition, and Optical Character Recognition (OCR).\nFollowing this, we compare and evaluate various PDF parsing libraries and tools in Section 2, including open-source libraries (Docling, Marker, MinerU, PyMuPDF) and closed-source solutions (LlamaParse, Gemini, Mistral). We provide a detailed comparison based on a qualitative analysis using a diverse set of test PDFs (slides, reports, scanned documents, and documents with complex tables). The results of this analysis are available through an interactive demo that visualizes the differences between PDF input and Markdown output for each parsing solution."
  },
  {
    "objectID": "posts/pdf-parsing/pdf-parsing.html#sec-docling",
    "href": "posts/pdf-parsing/pdf-parsing.html#sec-docling",
    "title": "PDF Parsing for LLM Input",
    "section": "Docling: A Modular PDF Processing Pipeline",
    "text": "Docling: A Modular PDF Processing Pipeline\nOverview\nDocling is a modular and extensible pipeline designed to ingest various document formats, primarily PDFs (but also DOCX, HTML, etc.), and transform them into a unified, structured representation: the DoclingDocument. The core aim is to create a standardized representation suitable for downstream tasks, such as feeding data into an LLM. Docling is in active development and is completely open-source. It provides a comprehensive technical documentation (Auer et al. 2024), (Livathinos et al. 2025).\n\n\n\n\n\n\nFigure 1: Sketch of Docling’s default processing pipeline. Source: (Auer et al. 2024)\n\n\n\nThe Docling pipeline, as shown in Figure 1, consists of the following stages:\n\nPDF Backend (for raw PDF document processing)\nAI Models (Layout Analysis, Table Structure Recognition, OCR)\nAssembly and Post-processing\n\nPDF Backend\nThe PDF backend is responsible for:\n\nRetrieving all text content and their geometric coordinates on each page.\nRendering the visual representation of each page as it appears in a PDF viewer.\n\nThese capabilities are encapsulated in Docling’s PDF backend interface. Docling provides multiple backend choices, including a custom-built PDF parser based on the low-level qpdf library. This parser is open-sourced as a separate package, docling-parse, and powers Docling’s default PDF backend. Figure 2 illustrates the parsing process.\n\n\n\n\n\n\n\n\nOriginal PDF page\n\n\n\n\n\n\n\nParsed PDF page\n\n\n\n\n\n\nFigure 2: Illustration of docling parse from source.\n\n\n\nThe docling-parse package provides a Python interface to extract text content, images, and annotations from PDFs. It also supports rendering PDF pages as images. The extracted content is serialized to JSON Listing 1, which can be further processed by downstream components.\n\n\n\nListing 1: Example of docling-parse JSON output\n\n\n{'annotations': [{'/A': {'/IsMap': False,\n    '/S': '/URI',\n    '/URI': 'https://www.deloitte.com/global/en/Industries/financial-services/perspectives/pushing-through-undercurrents.html'},\n   '/BS': {'/S': '/S', '/Type': '/Border', '/W': 0},\n   '/Border': [0, 0, 0],\n   '/H': '/N',\n   '/Rect': [474.409, 580.322, 512.947, 569.083],\n   '/Subtype': '/Link',\n   '/Type': '/Annot'},\n  {'/A': {'/IsMap': False,\n    '/S': '/URI',\n    '/URI': 'https://www.deloitte.com/global/en/Industries/financial-services/perspectives/pushing-through-undercurrents.html'},\n   '/BS': {'/S': '/S', '/Type': '/Border', '/W': 0},\n   '/Border': [0, 0, 0],\n   '/H': '/N',\n   '/Rect': [67.9417, 568.322, 286.919, 557.22],\n   '/Subtype': '/Link',\n   '/Type': '/Annot'}],\n 'original': {'cells': {'data': [[36.142,\n     711.041,\n     54.862,\n     739.753,\n     36.142,\n     711.041,\n     54.862,\n     711.041,\n     54.862,\n     739.753,\n     36.142,\n     739.753,\n     'P',\n     -1,\n     8.32,\n     '/WinAnsiEncoding',\n     'WINANSI',\n     '/TT0',\n     '/FSUTKX+OpenSans-Light',\n     False,\n     True],\n    [54.542,\n     711.041,\n     73.422,\n     739.753,\n     54.542,\n     711.041,\n     73.422,\n     711.041,\n     73.422,\n     739.753,\n     54.542,\n     739.753,\n     'u',\n     -1,\n\n\n\nAI Models\nDocling integrates several AI models for layout analysis and table structure recognition (TableFormer (Nassar et al. 2022)). Pre-trained weights (hosted on Hugging Face) and a separate package for inference code (docling-ibm-models) are available.\nLayout Analysis Model\nThis model detects and classifies various elements on a page image by predicting bounding boxes. The architecture is based on RT-DETR and retrained on DocLayNet (Pfitzmann et al. 2022) and proprietary datasets. The Docling pipeline uses page images at 72 dpi resolution. Bounding box proposals are post-processed to remove overlaps based on confidence and size and then intersected with text tokens to group them into meaningful units (e.g., paragraphs, section titles, tables).\nRT-DETR (Real-Time DEtection TRansformer) is an object detection system using a hybrid encoder to process image features and IoU-aware query selection to focus on important parts of the image.\nTable Structure Recognition\n\n\n\n\n\n\nFigure 3: TableFormer architecture. Source: DS4SD/docling-ibm-models\n\n\n\nThe TableFormer model (a vision transformer) recovers table structure Figure 3. It predicts the logical row and column structure of a table based on an input image, determining which cells belong to column headers, row headers, or the table body. TableFormer handles tables with partial or no borderlines, empty cells, row or column spans, and other complexities.\nThe Docling pipeline feeds table objects detected in the layout analysis to the TableFormer model. TableFormer structure predictions are matched back to the PDF cells to avoid re-transcription of text in the table image.\nOCR (Optical Character Recognition)\nDocling optionally supports OCR for scanned PDFs or content in embedded bitmaps. Docling supports multiple OCR engines such as EasyOCR, Tesseract, RapidOCR, and OcrMac. By default, Docling feeds a high-resolution page image (216 dpi) to the OCR engine to capture small print details.\nAssembly and Post-processing\nIn the final stage, Docling assembles all prediction results into a DoclingDocument, defined in the docling-core package. This document object is then passed through a post-processing model that augments features, such as:\n\nDocument language detection\nReading order correction\nMatching figures with captions\nLabeling metadata (title, authors, references)\n\nThe final output can be serialized to JSON or transformed into Markdown.\nAdditional post-processing steps can include:\n\nClassification of figures.\nIdentification of code blocks or formulas.\nAnnotation of pictures with LLMs (example).\n\nThe DoclingDocument is a unified representation designed to encapsulate document structure and content in a standardized way. It’s a Pydantic datatype supporting text, tables, pictures, and more. It distinguishes between the main body and auxiliary elements (“furniture”). It retains layout information (bounding boxes) and provenance information. The DoclingDocument structure is organized into content items (texts, tables, pictures) and content structure (body, furniture, groups) Figure 4.\n\n\n\n\n\n\nFigure 4: DoclingDocument structure. Source: DS4SD/docling documentation"
  },
  {
    "objectID": "posts/pdf-parsing/pdf-parsing.html#sec-marker-pdf",
    "href": "posts/pdf-parsing/pdf-parsing.html#sec-marker-pdf",
    "title": "PDF Parsing for LLM Input",
    "section": "Marker-PDF: Accurate PDF Conversion",
    "text": "Marker-PDF: Accurate PDF Conversion\nMarker-pdf pipeline is another interesting option for PDF parsing. Raw extraction is done by pdftext, which is based on pypdfium2. Then, it uses Surya Surya GitHub. Surya is a document OCR toolkit that performs:\n\nOCR in 90+ languages.\nLine-level text detection in any language.\nLayout analysis (table, image, header, etc. detection).\nReading order detection.\nTable recognition (detecting rows/columns).\nLaTeX OCR.\n\nThe JSON output format from Surya is illustrated in Listing 2. This structured output includes detailed information about page dimensions, blocks of text, and individual spans with their corresponding bounding boxes, font information, and text content. Marker itself converts PDFs and images to markdown, JSON, and HTML. The key features of Marker include:\n\nSupports a range of documents in all languages.\nFormats tables, forms, equations, links, references, and code blocks.\nExtracts and saves images along with the markdown.\nRemoves headers/footers/other artifacts.\nEasily extensible with custom formatting and logic.\nOptionally boosts accuracy with an LLM.\nWorks on GPU, CPU, or MPS.\n\n\n\n\nListing 2: Example of Surya JSON output\n\n\n[\n  {\n    \"page\": 0,\n    \"bbox\": [\n      0,\n      0,\n      595.2760009765625,\n      841.8900146484375\n    ],\n    \"width\": 596,\n    \"height\": 842,\n    \"rotation\": 0,\n    \"blocks\": [\n      {\n        \"lines\": [\n          {\n            \"spans\": [\n              {\n                \"bbox\": [\n                  36.14179992675781,\n                  99.6307373046875,\n                  481.22967529296875,\n                  131.6307373046875\n                ],\n                \"text\": \"Pushing through undercurrents\",\n                \"rotation\": 0,\n                \"font\": {\n                  \"name\": \"OpenSans-Light\",\n                  \"flags\": 524320,\n                  \"size\": 1,\n                  \"weight\": 240\n                },\n                \"char_start_idx\": 0,\n                \"char_end_idx\": 28,\n                \"url\": \"\"\n              },\n              {\n                \"bbox\": [\n                  466.78369140625,\n                  125.09466552734375,\n                  466.78369140625,\n                  125.09466552734375\n                ],\n                \"text\": \"\\n\",\n                \"rotation\": 0,\n                \"font\": {\n                  \"name\": \"\",\n                  \"flags\": 0,\n                  \"size\": 1,\n                  \"weight\": -1\n                },\n                \"char_start_idx\": 29,\n                \"char_end_idx\": 30,\n                \"url\": \"\"\n              }\n            ],\n            \"bbox\": [\n              36.14179992675781,\n              99.6307373046875,\n              481.22967529296875,\n              131.6307373046875\n            ]\n          }\n        ],\n..."
  },
  {
    "objectID": "posts/pdf-parsing/pdf-parsing.html#sec-mineru",
    "href": "posts/pdf-parsing/pdf-parsing.html#sec-mineru",
    "title": "PDF Parsing for LLM Input",
    "section": "MinerU: Multi-Module Document Parsing",
    "text": "MinerU: Multi-Module Document Parsing\n\n\n\n\n\n\nFigure 5: Overview of the MinerU framework processing workflow.\n\n\n\nMinerU is a multi-module document parsing framework that uses a multi-stage approach, employing various document parsing models to process document images. The code repository is available at the MinerU GitHub Repository, and technical details can be found in the reference paper (Wang et al. 2024). MinerU provides source code, models, and documentation for parsing various document formats efficiently.\nThe MinerU framework processing workflow (Figure 5) consists of four stages:\n\nDocument Preprocessing: Uses PyMuPDF to read PDF files, filters out unprocessable files, and extracts PDF metadata (parseability, language type, page dimensions).\nDocument Content Parsing: Employs the PDF-Extract-Kit library for layout analysis (layout and formula detection). Applies different recognizers to various regions: OCR for text and titles, formula recognition for formulas, and table recognition for tables.\nDocument Content Post-Processing: Removes invalid regions, stitches content according to regional positioning, and obtains positioning, content, and sorting information for different document regions.\nFormat Conversion: Generates user-required formats, such as Markdown, for subsequent use.\n\nDocument Preprocessing\nThis stage focuses on filtering unprocessable PDFs and obtaining PDF metadata:\n\nLanguage Identification: Currently processes Chinese and English documents.\nContent Garbled Detection: Identifies text-based PDFs with garbled text.\nScanned PDF Identification: Distinguishes between text-based and scanned PDFs.\nPage Metadata Extraction: Extracts document metadata such as total page count, page dimensions, and other attributes.\n\nDocument Content Parsing\nMinerU uses the PDF-Extract-Kit model library to detect different types of regions and recognize their content:\n\nLayout Analysis: Identifies different types of elements and their regions on a page.\nFormula Detection: Detects inline and displayed formulas.\nFormula Recognition: Recognizes formula images into LaTeX source code using the UniMERNet model.\nTable Recognition: Extracts tabular data from visual table images using TableMaster and StructEqTable.\nOCR: Applies Paddle-OCR to recognize text regions.\n\nDocument Content Post-Processing\nThis stage addresses content ordering by handling the relationships between Bounding Boxes (BBoxes):\n\nContainment Relationships: Removes formulas and text blocks contained within image and table regions.\nPartial Overlap Relationships: Shrinks partially overlapping text boxes and ensures the integrity of text when overlapping with tables/images.\nSegmentation Algorithm: Divides the page into regions based on human reading order (“top to bottom, left to right”).\n\nModels Overview\n\n\n\nTable 1: MinerU models overview\n\n\n\n\n\n\n\n\n\n\nTask Type\nDescription\nModels\n\n\n\n\nLayout Detection\nLocate different elements in a document: including images, tables, text, titles, formulas\nDocLayout-YOLO_ft, YOLO-v10_ft, LayoutLMv3_ft\n\n\nFormula Detection\nLocate formulas in documents: including inline and block formulas\nYOLOv8_ft\n\n\nFormula Recognition\nRecognize formula images into LaTeX source code\nUniMERNet\n\n\nOCR\nExtract text content from images (including location and recognition)\nPaddleOCR\n\n\nTable Recognition\nRecognize table images into corresponding source code (LaTeX/HTML/Markdown)\nPaddleOCR+TableMaster, StructEqTable"
  },
  {
    "objectID": "posts/pdf-parsing/pdf-parsing.html#pdf-sample-dataset",
    "href": "posts/pdf-parsing/pdf-parsing.html#pdf-sample-dataset",
    "title": "PDF Parsing for LLM Input",
    "section": "PDF Sample Dataset",
    "text": "PDF Sample Dataset\nWe test the different PDF parsing options on a small but diverse dataset of PDFs. These PDFs are available at the following link: PDF Parsing Dataset. The dataset contains different types of PDFs to cover various difficulties faced by PDF parsers:\n\nSlides\nImage-only PDFs (requiring OCR)\nReports\nTables\n\nThe PDF files located in the pdfs directory were sourced from the following locations:\n\nXC9500_CPLD_Family-1-4.pdf: Downloaded from https://media.digikey.com/pdf/Data%20Sheets/AMD/XC9500_CPLD_Family.pdf\n2023-conocophillips-aim-presentation-1-7.pdf: Downloaded from https://static.conocophillips.com/files/2023-conocophillips-aim-presentation.pdf\n\nThe following four PDF files are sourced from the RAG blog benchmark, specifically from the associated Google Drive folder:\n\ngx-iif-open-data.pdf\ndeloitte-tech-risk-sector-banking.pdf\nlife-sciences-smart-manufacturing-services-peak-matrix-assessment-2023.pdf\ndttl-tax-technology-report-2023.pdf"
  },
  {
    "objectID": "posts/pdf-parsing/pdf-parsing.html#qualitative-results",
    "href": "posts/pdf-parsing/pdf-parsing.html#qualitative-results",
    "title": "PDF Parsing for LLM Input",
    "section": "Qualitative Results",
    "text": "Qualitative Results\nNote: The following results are based on a limited set of tests and should be considered indicative rather than scientifically rigorous.\n\nYou can directly compare the output Markdown results at the Hugging Face Space demo: pdf-parsing-demo.\n\nDocling provides decent results for text extraction, layout analysis, and table recognition. The OCR support is also a valuable addition for scanned PDFs. Very recently, it provides support for image description example, which is a very promising feature.\n\n\n\n\n\n\nFigure 6: Docling parsing results\n\n\n\nLlamaParse in default mode also provides good results. It provides descriptions of charts and images and is able to extract tables. However, the quality of the chart and image descriptions is not top-tier. It is also a closed-source solution.\n\n\n\n\n\n\nFigure 7: LlamaParse parsing results\n\n\n\nMarker provides good results and a description of the images using Gemini.\n\n\n\n\n\n\nFigure 8: Marker parsing results\n\n\n\nPyMuPDF in default mode is a more raw extraction approach, parsing the raw content. The other libraries tend to build upon more fundamental extraction libraries such as PyMuPDF. The results generally require further refinement.\n\n\n\n\n\n\nFigure 9: Pymupdf parsing results\n\n\n\nGemini is very good at parsing the content and providing a description of the images. It is versatile and effective. However, it is closed source.\n\n\n\n\n\n\nFigure 10: Gemini parsing results\n\n\n\n\n\n\n\n\n\nFigure 11: Gemini parsing results (suppl.)\n\n\n\nMistral OCR is a closed-source solution that provides good results. It is particularly effective at extracting text and tables. However, it does not support image description by default.\n\n\n\n\n\n\nFigure 12: Mistral parsing results\n\n\n\nMinerU is not part of the app because it is not easy to split the output by page, and tables are under HTML format. However, the results are good, and the layout is very good. It doesn’t support image description. MinerU is a very promising library.\n\n\n\n\n\n\nFigure 13: MinerU parsing results\n\n\n\nWe tested unstructured (free version), which did not produce satisfying results.\nMarkitdown is a very new library that we did not test. It seems to rely on ad-hoc solutions and is simply an aggregator of solutions.\nWe also tested (not extensively) some cloud-based solutions for PDF parsing such as Adobe PDF Extract API, AWS Textract and Azure AI Document intelligence but we were not convinced by the first results. Apparently, they seem to be very good at extracting for large quantity of pdf following the same template.\nIn terms of table extraction capabilities, we tested Camelot, a specialized library specifically designed for extracting tables from PDFs. Camelot excels at handling both lattice and stream type tables, making it particularly effective for complex table extraction tasks. The library is well-documented and maintained, with comprehensive documentation available on their GitHub repository. The results were good for table extraction. Camelot is a dedicated library for tables.\nConclusion: The choice of PDF parsing library depends on the specific requirements of the task at hand. or general-purpose parsing with a strong emphasis on image understanding, consider Gemini. However, be aware that this is a closed-source solution. If an open-source solution is preferred, Docling, Marker and MinerU are strong contenders. For tasks requiring specialized table extraction, Camelot is a reliable choice."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Why I Write\nWelcome to my blog, a personal space where I share notes on my work and explorations in science, machine learning, and the broader tech landscape. These posts serve as a journal for my thoughts and discoveries, but I hope they also provide value and inspiration to anyone interested in these dynamic fields. Whether you’re a fellow researcher, a tech enthusiast, or simply curious, I invite you to explore and engage with the ideas I present here. Feel free to reach out if you’d like to connect or collaborate on exciting projects !\nShort Bio\nI am a Data Scientist with expertise in applied mathematics and artificial intelligence. My professional experience spans diverse domains, including signal processing and anomaly detection at Thales, as well as drug discovery at Iktos. Throughout my career, I have been deeply involved in research and development, driven by a passion for innovation and the challenge of addressing complex problems."
  },
  {
    "objectID": "posts/mhc/mhc.html",
    "href": "posts/mhc/mhc.html",
    "title": "Predicting MHC-Peptide Binding with Machine Learning",
    "section": "",
    "text": "This blog post explores the application of machine learning techniques to predict the binding affinity between peptides and Major Histocompatibility Complex (MHC) molecules. In Section 1, we introduce the biological aspects of MHC. In Section 2, we then present the deep learning approach and the results of MHC antigen presentation."
  },
  {
    "objectID": "posts/mhc/mhc.html#mhc-class-i-and-class-ii",
    "href": "posts/mhc/mhc.html#mhc-class-i-and-class-ii",
    "title": "Predicting MHC-Peptide Binding with Machine Learning",
    "section": "MHC Class I and Class II",
    "text": "MHC Class I and Class II\nMHC molecules are divided into two main classes: MHC class I and MHC class II.\nMHC Class I\nMHC class I molecules are present on most cells (except red blood cells). They present antigens from inside the cell. When a cell is infected or becomes cancerous, proteins within the cell are broken down into smaller fragments called epitopes. These epitopes are loaded onto MHC class I molecules and displayed on the cell surface. Killer T cells (cytotoxic T lymphocytes or CTLs) recognize these epitopes and can destroy infected or cancerous cells.\n\n\n\n\n\n\nFigure 1: MHC class I pathway: Proteins in the cytosol are degraded by the proteasome, liberating peptides internalized by TAP channel in the endoplasmic reticulum, there associating with MHC-I molecules freshly synthesized. MHC-I/peptide complexes enter Golgi apparatus, are glycosylated, enter secretory vesicles, fuse with the cell membrane, and externalize on the cell membrane interacting with T lymphocytes. This figure shows the detailed steps of how MHC Class I molecules get loaded. Source\n\n\n\nIn humans, the main MHC class I molecules are HLA-A, HLA-B, and HLA-C (HLA stands for Human Leukocyte Antigen).\nMHC Class II\nMHC class II molecules are primarily found on specialized immune cells called antigen-presenting cells (APCs) like macrophages, dendritic cells, and B cells. They present antigens from outside the cell. APCs engulf foreign invaders and break them down into epitopes in a process called phagocytosis. These epitopes are loaded onto MHC class II molecules and displayed on the cell surface. Helper T cells recognize these epitopes and activate other immune cells to fight the infection. These Helper T cells have receptors that specifically bind to MHC Class II molecules. If a helper T cell recognizes a foreign epitope presented by MHC class II, it becomes activated and starts to coordinate the immune response. It releases chemical signals (cytokines) that help other immune cells, like B cells and killer T cells, to fight off the infection.\n\n\n\n\n\n\nFigure 2: This diagram shows how MHC class I molecules present antigens from inside the cell to cytotoxic T cells (CD8+), leading to the destruction of infected cells. Notice how the antigen is processed inside the cell and then presented on the cell surface. On the contrary, MHC class II molecules present antigens from outside the cell to helper T cells (CD4+), which then activate other immune cells. Notice how this differs from MHC class I, which presents antigens from inside the cell.(Antunes et al. 2018)\n\n\n\n\n\n\n\n\n\nFigure 3: Molecular structures of class I and class II MHCs. Molecular representation of a class I MHC (A, C) and a class II MHC (B, D). The upper panel shows a top view, while the bottom panel shows a cross section side-view of the binding clefts. Note that the binding cleft of a class I receptor is deeper, with “closed” extremities, while the class II cleft is shallower, with open extremities. The pockets involved in binding primary “anchor” residues are indicated. Together, structural differences in the shape of the cleft and the location of binding pockets have an impact on the overall conformation of bound ligands (e.g., peptides tend to adopt bulged conformations when bound to class I, and more linear conformations when bound to class II). (Antunes et al. 2018)\n\n\n\nIn humans, the main MHC class II molecules are HLA-DP, HLA-DQ, and HLA-DR.\nHuman Leukocyte Antigens (HLA)\nIn humans, MHC molecules are called Human Leukocyte Antigens (HLAs). The genes for HLA proteins are located within the MHC region on chromosome 6.\nHLAs are important for:\n\nOrgan transplantation: HLA matching is crucial to prevent organ rejection.\nAutoimmune diseases: Certain HLA types are associated with increased risk of autoimmune diseases.\nDrug responses: HLA variations can influence how individuals respond to certain medications.\nEvolutionary advantage: HLA diversity is important for population survival against various pathogens.\n\n\n\n\n\n\n\nFigure 4: Codominant expression of HLA genes. Each person inherits HLA genes from both parents, resulting in the expression of multiple HLA types. This increases the diversity of antigens that can be presented. Source\n\n\n\nMHC Diversity\nThe MHC is highly diverse, with many different versions (alleles) of each MHC gene. This diversity is essential because different MHC molecules bind to different peptides. A diverse population is more likely to have individuals who can present antigens from new pathogens, ensuring better survival chances for the species."
  },
  {
    "objectID": "posts/mhc/mhc.html#datasets",
    "href": "posts/mhc/mhc.html#datasets",
    "title": "Predicting MHC-Peptide Binding with Machine Learning",
    "section": "Datasets",
    "text": "Datasets\nThe IPD-IMGT/HLA Database is a specialized resource focusing on the sequences of the human major histocompatibility complex (MHC) or human leukocyte antigen (HLA) system. It provides comprehensive information about HLA alleles, including their sequences, nomenclature, and associated metadata. This database is crucial for researchers in immunology, transplantation, and vaccine development, as accurate HLA typing is essential for understanding immune responses and predicting transplant compatibility. The IEDB (Immune Epitope Database) is a widely used resource for curated experimental data on immune epitopes. It catalogs epitopes recognized by T cells and B cells in various diseases and conditions. The IEDB facilitates research in epitope discovery, vaccine design, and understanding immune recognition, offering tools and data for analyzing and predicting immune responses."
  },
  {
    "objectID": "posts/mhc/mhc.html#relevance-to-machine-learning",
    "href": "posts/mhc/mhc.html#relevance-to-machine-learning",
    "title": "Predicting MHC-Peptide Binding with Machine Learning",
    "section": "Relevance to Machine Learning",
    "text": "Relevance to Machine Learning\nThe interaction between an MHC molecule and a peptide is highly dependent on the amino acid sequence of the peptide and the specific type of MHC molecule. This sequence-structure-function relationship makes MHC-peptide binding prediction a suitable problem for machine learning. Experimental data on MHC-peptide binding affinities, though sometimes sparse, is available for training and evaluating predictive models. The high polymorphism of MHC genes, with numerous variants (alleles) existing in the population, adds complexity and motivates the development of specific prediction models.\nKey MHC Concepts:\n\nMHC Class I and Class II: The two main classes of MHC molecules.\nEpitope: The specific part of the peptide recognized by the T cell receptor.\nPolymorphism: The existence of multiple versions (alleles) of MHC genes within a population. Different MHC alleles bind to different sets of peptides.\nBinding Affinity: The strength of the interaction between an MHC molecule and a peptide. Often measured experimentally, it serves as the target variable for many machine learning models.\n\nMachine Learning Approaches\nMHC-peptide binding prediction aims to develop models that accurately predict the binding affinity between a given peptide sequence and a specific MHC allele. This can be framed as a regression or classification task.\n\nInput: Peptide sequence, MHC allele (represented as a sequence or encoding).\nOutput: Binding affinity (e.g., IC50 value, Kd value) or a binary label (binder/non-binder).\n\nFeature engineering and model selection are crucial for building effective predictors. Common approaches include:\n\nSequence-based Features: Amino acid composition, n-grams, physicochemical properties.\nStructure-based Features: (If available) Information about the 3D structure of the MHC-peptide complex.\nMHC Allele Encoding: Techniques such as one-hot encoding, amino acid embeddings, or other methods to represent the MHC allele sequence.\nMachine Learning Algorithms: Linear regression, Support Vector Machines (SVMs), Random Forests, Neural Networks (including Convolutional Neural Networks and Transformers)."
  },
  {
    "objectID": "posts/mhc/mhc.html#project-overview",
    "href": "posts/mhc/mhc.html#project-overview",
    "title": "Predicting MHC-Peptide Binding with Machine Learning",
    "section": "Project Overview",
    "text": "Project Overview\n\n\n\n\n\n\nNote\n\n\n\nThe code is available at https://github.com/nbrosse/mhcpred.\n\n\nThe goal of this project is to build a machine learning classifier that predicts whether a given peptide will be presented by a specific MHC class I protein, identified by its allele name. The data used for this project is derived from the training and evaluation data of NetMHCPan4.1 (Reynisson et al. 2020), a well-established framework for MHC binding prediction. The data is split into training and testing sets, with the training data further divided into five folds for cross-validation.\nThe dataset contains a binary target variable, “hit” (1 if the peptide is presented by the MHC, 0 otherwise), and two features:\n\n“peptide”: The amino acid sequence of the peptide. These short chains of amino acids are potential antigens that could be presented to the immune system.\n“allele”: The name of the MHC class I allele. MHC molecules are highly polymorphic, meaning there are many different versions (alleles) within the human population. Each allele has a slightly different binding groove, affecting which peptides it can bind and present. You can find details on the naming convention here (nomenclature).\n\n\n\n\n\n\n\nNote\n\n\n\nPredicting MHC antigen presentation is a complex field. This project provides a simplified introduction to the problem. For a more in-depth understanding, we recommend exploring NetMHCPan (Reynisson et al. 2020) and MHCflurry (O’Donnell, Rubinsteyn, and Laserson 2020) and the references cited within those publications. Note that the specific data used in this project is derived from NetMHCPan4.1 but must remain private.\n\n\nWe begin with Exploratory Data Analysis (EDA) to understand the characteristics of our data.\n\nEDA\n\n# Import data loading functions\nfrom mhcpred.data import get_train_data, get_test_data\n\n# Load training and test data\ndf_train = get_train_data()\ndf_test = get_test_data()\n\n\n# View first few rows of training data\ndf_train.head()\n\n\n\n\n\n\n\n\npeptide\nallele\nhit\nfold\n\n\n\n\n0\nYFPLAPFNQL\nHLA-C*14:02\nTrue\n0\n\n\n1\nKESKINQVF\nHLA-B*44:02\nTrue\n0\n\n\n2\nQPHDPLVPLSA\nHLA-B*54:01\nTrue\n0\n\n\n3\nRTIADSLINSF\nHLA-B*57:03\nTrue\n0\n\n\n4\nEEKTIIKKL\nHLA-B*44:03\nTrue\n0\n\n\n\n\n\n\n\n\n# Get allele counts in training data\ndf_train[[\"allele\"]].value_counts()\n\nallele     \nHLA-A*02:01    265252\nHLA-B*07:02    201038\nHLA-B*57:01    184773\nHLA-A*29:02    181136\nHLA-B*40:02    145817\n                ...  \nHLA-A*69:01        12\nHLA-A*02:06         6\nHLA-A*26:02         6\nHLA-A*26:03         6\nHLA-A*25:01         6\nName: count, Length: 130, dtype: int64\n\n\n\ndf_test[\"allele\"].value_counts()\n\nallele\nHLA-A*02:02    77053\nHLA-A*02:06    54510\nHLA-A*02:11    48445\nHLA-B*53:01    46991\nHLA-B*15:17    45917\nHLA-A*02:05    45136\nHLA-B*15:03    44968\nHLA-A*33:01    43333\nHLA-A*66:01    41538\nHLA-C*12:03    36448\nHLA-C*03:03    35568\nHLA-A*11:01    33424\nHLA-A*30:02    33180\nHLA-C*08:02    32416\nHLA-A*23:01    30467\nHLA-A*32:01    28036\nHLA-B*40:02    23768\nHLA-B*14:02    21601\nHLA-B*37:01    20048\nHLA-B*40:01    18908\nHLA-B*45:01    18750\nHLA-B*18:01    18284\nHLA-B*58:01    17946\nHLA-B*15:02    16702\nHLA-B*15:01    16624\nHLA-A*30:01    15837\nHLA-C*07:02    15293\nHLA-B*46:01    14015\nHLA-B*38:01     9509\nHLA-B*35:03     8275\nHLA-A*26:01     7730\nHLA-C*05:01     7033\nHLA-A*25:01     6906\nHLA-A*68:01     5648\nHLA-B*08:01     3365\nHLA-B*07:02     2469\nName: count, dtype: int64\n\n\n\n# Get positive samples per allele in training\ndf_train.groupby(\"allele\").hit.sum()\n\nallele\nHLA-A*01:01     7156\nHLA-A*01:03        7\nHLA-A*02:01    13025\nHLA-A*02:03     1873\nHLA-A*02:04     3155\n               ...  \nHLA-C*12:04        3\nHLA-C*14:02     2441\nHLA-C*15:02     1873\nHLA-C*16:01     2970\nHLA-C*17:01      602\nName: hit, Length: 130, dtype: int64\n\n\n\ndf_train.hit.sum()\n\n197547\n\n\n\nlen(df_train)\n\n3679405\n\n\n\n# ~5.37% positive rate\ndf_train.hit.sum() / len(df_train)\n\n0.05368993084479692\n\n\n\ndf_test.groupby(\"allele\").hit.sum()\n\nallele\nHLA-A*02:02    3063\nHLA-A*02:05    2016\nHLA-A*02:06    1975\nHLA-A*02:11    2035\nHLA-A*11:01    2309\nHLA-A*23:01    1697\nHLA-A*25:01     396\nHLA-A*26:01     555\nHLA-A*30:01     892\nHLA-A*30:02    2415\nHLA-A*32:01    1436\nHLA-A*33:01    2138\nHLA-A*66:01    1988\nHLA-A*68:01     433\nHLA-B*07:02     159\nHLA-B*08:01     180\nHLA-B*14:02    1056\nHLA-B*15:01     769\nHLA-B*15:02     637\nHLA-B*15:03    1953\nHLA-B*15:17    1712\nHLA-B*18:01     784\nHLA-B*35:03     330\nHLA-B*37:01    1253\nHLA-B*38:01     619\nHLA-B*40:01    1268\nHLA-B*40:02    1333\nHLA-B*45:01     760\nHLA-B*46:01     575\nHLA-B*53:01    2016\nHLA-B*58:01     866\nHLA-C*03:03    2003\nHLA-C*05:01     383\nHLA-C*07:02     593\nHLA-C*08:02    1546\nHLA-C*12:03    1273\nName: hit, dtype: int64\n\n\n\ndf_test.hit.sum() / len(df_test)\n\n0.04800130213150049\n\n\n\n# Find alleles only in test set\nset(df_test.allele.unique()) - set(df_train.allele.unique())\n\n{'HLA-A*02:02', 'HLA-A*02:11', 'HLA-A*33:01', 'HLA-B*53:01'}\n\n\n\nDataset Class Imbalance\n\nTraining Set:\n\nTotal samples: 3,679,405\nPositive rate: 5.37%\n\nTest Set:\n\nTotal samples: 453,934\nPositive rate: 4.8%\n\n\nAllele Distribution\n\nMost frequent: HLA-A*02:01 (265,252 samples)\nLeast frequent: Multiple alleles with only 6 samples\nDistribution: Highly imbalanced across alleles\n\nTest-Only Alleles\n\nHLA-A*02:02\nHLA-A*02:11\nHLA-A*33:01\nHLA-B*53:01\n\n\nSource: EDA\n\nUsing MHCflurry Pretrained Models for Prediction\nWe leverage the mhcflurry package to build our classifier. MHCflurry is a tool specifically designed for MHC binding affinity prediction. See also the associated paper (O’Donnell, Rubinsteyn, and Laserson 2020). MHCflurry is a software package focused on predicting how strongly peptides bind to MHC class I molecules. It’s based on machine learning models trained on a large dataset of experimentally measured peptide-MHC binding affinities. The current version uses neural networks trained with a mix of binding affinity and mass spectrometry data (ligand presentation).\nWe use the Binding Affinity pretrained model from mhcflurry to predict the binding affinity of peptides to MHC class I molecules using Class1AffinityPredictor. The following code assumes you have installed mhcflurry and downloaded the required pretrained models.\nmhcflurry-downloads fetch models_class1_presentation\npython scripts/mhcflurry_benchmark.py\ndef predict_with_mhcflurry() -&gt; pd.DataFrame:\n    predictor = Class1AffinityPredictor.load()\n    df_test = get_test_data()\n    mhcflurry_predictions = predictor.predict_to_dataframe(\n        peptides=df_test.peptide.values,\n        alleles=df_test.allele.values,\n        allele=None,\n    )\n    df = pd.merge(df_test, mhcflurry_predictions, on=[\"allele\", \"peptide\"], how=\"left\")\n    df.to_csv(str(output_path / \"mhcflurry_predictions.csv\"), index=False)\n    return df\nThe output is of the form:\n\n\n\nTable 1: MHCflurry pretrained model predictions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npeptide\nhit\nallele\nprediction\nprediction_low\nprediction_high\nprediction_percentile\n\n\n\n\nAAPATRAAL\nTrue\nHLA-B*35:03\n94.297\n59.902\n144.624\n0.205\n\n\nAAPSAAREL\nTrue\nHLA-B*35:03\n116.19\n79.847\n169.241\n0.262\n\n\nAEISQIHQSVTD\nTrue\nHLA-B*35:03\n26103.26\n22695.389\n28415\n15.739\n\n\nALEEQLQQIRAE\nTrue\nHLA-B*35:03\n24797.131\n19988.967\n28062.65\n13.571\n\n\nAQDPLLLQM\nTrue\nHLA-B*35:03\n2164.336\n745.888\n5390.727\n1.413\n\n\nASAPPGPPA\nTrue\nHLA-B*35:03\n1398.729\n387.675\n3293.692\n1.157\n\n\nDAHKGVAL\nTrue\nHLA-B*35:03\n84.315\n54.736\n133.899\n0.175\n\n\nDNPIQTVSL\nTrue\nHLA-B*35:03\n1386.767\n565.122\n3667.21\n1.151\n\n\nDPEAFLVQI\nTrue\nHLA-B*35:03\n245.485\n133.986\n394.752\n0.484\n\n\n\n\n\n\nThe first 3 columns come from the test dataset.\n\npeptide: The amino acid sequence of the peptide being evaluated.\nhit: The ground truth, a boolean value indicating whether the peptide is known to be presented by the given MHC allele (True) or not (False).\nallele: The name of the MHC class I allele being considered.\n\nThe following columns are added by the binding affinity predictions:\n\nprediction: The raw prediction score from the MHCflurry model. Higher values generally indicate a stronger predicted binding affinity. These values are not directly interpretable in isolation.\nprediction_low/prediction_high: These represent the lower and upper bounds of a 95% confidence interval around the prediction value. They provide an estimate of the uncertainty associated with the prediction.\nprediction_percentile: This is the most useful column for interpreting the results. It represents the percentile rank of the prediction score compared to a background distribution of scores for random peptides. A lower percentile indicates a stronger predicted binding affinity. For example, a percentile of 1.0 means that the predicted score is in the top 1% of all possible scores.\n\nThe uncertainty estimation comes from the ensemble of neural networks used for the prediction. A percentile threshold (e.g., 2%) is commonly used to determine whether a peptide is likely to bind (lower is better).\n\n\nPrediction: Fitting a Class1BinaryNeuralNetwork\nWe now fit a Class1BinaryNeuralNetwork on the training dataset. The code is available at https://github.com/nbrosse/mhcpred.\nHere’s a glimpse of the training data structure:\n\n\n\nTable 2: Training data.\n\n\n\n\n\npeptide\nallele\nhit\n\n\n\n\nYFPLAPFNQL\nHLA-C*14:02\nTrue\n\n\nKESKINQVF\nHLA-B*44:02\nTrue\n\n\nQPHDPLVPLSA\nHLA-B*54:01\nTrue\n\n\nRTIADSLINSF\nHLA-B*57:03\nTrue\n\n\n\n\n\n\nChallenges arise in encoding the peptide and allele sequences for use in a neural network. Peptides have variable lengths, and alleles are represented by their names.\nThe MHCFlurry package provides a mapping between alleles and their corresponding MHC molecule sequences within the allele_sequences.csv file. This mapping is crucial for encoding the alleles.\n\n\n\nTable 3: Allele sequences.\n\n\n\n\n\nAllele\nSequence\n\n\n\n\nHLA-A*01:01\nYFAMYQENMAHTDANTLYGIIYDRDYTWVARVYRGYA\n\n\nHLA-A*01:02\nYSAMYQENMAHTDANTLYGIIYDRDYTWVARVYRGYA\n\n\nHLA-A*01:03\nYFAMYQENMAHTDANTLYGIMYDRDYTWVARVYRGYA\n\n\nHLA-A*01:04\nYFAMYQENMAHTDANTLYGIIYDRDYTWVARVYRGYX\n\n\nHLA-A*01:06\nYFAMYQENMAHTDANTLYGIIYDRDYTWVALAYRGYA\n\n\n\n\n\n\nFirst, we import necessary libraries. We also import components from our own mhcpred library, which contains the neural network architecture and data loading functions.\nimport pickle\nfrom pathlib import Path\nfrom typing import Iterator\n\nimport numpy as np\nimport pandas as pd\nfrom mhcflurry.allele_encoding import AlleleEncoding\nfrom mhcflurry.encodable_sequences import EncodableSequences\nfrom sklearn.model_selection import train_test_split\n\nfrom mhcpred.class1_binary_nn import Class1BinaryNeuralNetwork\nfrom mhcpred.config import settings\nfrom mhcpred.data import get_test_data, get_train_data\nfrom mhcpred.hyperparameters import base_hyperparameters\nWe load the allele sequences, training data, and test data using helper functions. The allele sequences are crucial for encoding the MHC alleles.\nallele_sequences = pd.read_csv(\n    str(data_path / \"allele_sequences.csv\"), index_col=0\n).iloc[:, 0]\n\ndf_total_train = get_train_data()\ndf_test = get_test_data()\nWe determine the alleles present in our data and filter the loaded allele sequences to only include those we’ll be using.\nalleles_in_use = set(df_total_train.allele).union(set(df_test.allele))\nallele_sequences_in_use = allele_sequences[allele_sequences.index.isin(alleles_in_use)]\nThe AlleleEncoding class is designed to cache encodings for a sequence of alleles. It maps allele names to integer indices and sequences, allowing consistent use of these mappings, especially as inputs to neural networks. The EncodableSequences class is used to encode variable-length peptides into fixed-size numerical matrices. It caches various encodings of a list of sequences and provides methods to encode these sequences into fixed-length categorical or vector representations.\nWe also split the training data into training and validation sets using train_test_split from sklearn. Stratified splitting ensures the class balance is maintained across the training and validation sets. The validation data is also preprocessed by encoding the peptides and alleles.\nallele_encoding = AlleleEncoding(\n    alleles=allele_sequences_in_use.index.values,\n    allele_to_sequence=allele_sequences_in_use.to_dict(),\n)\n\ndf_train, df_val = train_test_split(\n    df_total_train, test_size=0.1, shuffle=True, stratify=df_total_train.hit.values\n)\n\nval_peptides = EncodableSequences(df_val.peptide.values)\nval_alleles = AlleleEncoding(\n    alleles=df_val.allele.values,\n    allele_to_sequence=allele_sequences_in_use.to_dict(),\n)\nAlleleEncoding provides a robust and efficient way to manage and encode allele sequences. It handles the complexities of mapping allele names to indices, storing and padding sequences, and providing different encoding options. The AlleleEncoding class manages allele sequences efficiently:\n\nAllele Universe vs. Used Alleles: The class distinguishes between two sets of alleles:\n\n\nAllele Universe: The complete set of alleles the system knows about. This is defined by the allele_to_sequence dictionary, mapping allele names to their amino acid sequences.\nUsed Alleles: The specific set of alleles used in a particular analysis or task. This is provided as a list when creating an AlleleEncoding instance.\n\n\nallele_to_index Mapping: A dictionary (self.allele_to_index) is created to map each allele in the universe to a unique integer index. This includes a special index for None values, often used as padding. This mapping ensures consistency: the same allele always gets the same index.\nSequence Storage (self.sequences): The amino acid sequences for all alleles in the universe are stored in a Pandas Series (self.sequences). Critically, these sequences are padded to the same length using “X” characters. This padding is essential for creating fixed-length numerical representations, which many machine learning models require.\nBorrowing (borrow_from): The borrow_from parameter allows you to create a new AlleleEncoding instance that inherits the allele universe and mappings from an existing instance. This is a powerful way to ensure consistency across different parts of your code. You don’t have to redefine the allele_to_sequence mapping every time.\nEncoding: The class provides methods to encode the allele sequences into numerical matrices, suitable for machine learning.\n\n\nallele_representations(encoding_name): Encodes the entire allele universe. This is useful for pre-calculating encodings for all known alleles.\nfixed_length_vector_encoded_sequences(encoding_name): Encodes the used alleles (the subset provided when the object was initialized). This uses the pre-calculated encodings from allele_representations and selects only the encodings for the alleles in self.alleles, in the correct order. This gives you a matrix where each row represents an allele sequence.\n\n\nEncoding Methods (encoding_name): The type of encoding can be specified using the encoding_name parameter. Common options include “BLOSUM62” (a substitution matrix) and “one-hot” encoding.\n\nBLOSUM62 (Blocks Substitution Matrix) is a widely used substitution matrix in bioinformatics. It represents the likelihood of one amino acid being substituted for another during evolution. The matrix assigns a score to each pair of amino acids, reflecting their similarity. Higher scores indicate a higher probability of substitution (or that the two amino acids are more similar). Negative scores indicate substitutions that are less likely or even unfavorable.\nThe AlleleEncoding class uses BLOSUM62 to convert amino acid sequences into numerical representations. Each amino acid in the sequence is replaced by a vector of 21 numbers (20 amino acids + the “X” character). Each of these 21 numbers is the BLOSUM62 score between the amino acid in the sequence and the amino acid represented by the position in the 21-element vector.\n\nAmino Acid Indexing: First, each amino acid is converted to an index. There’s a mapping from amino acid letter to index.\nBLOSUM62 Lookup: For each amino acid in the sequence, the code looks up its corresponding row in the BLOSUM62 matrix. This row represents the similarity scores between that amino acid and all other amino acids (and ‘X’).\nVector Representation: The row from the BLOSUM62 matrix becomes the vector representation of that amino acid. So, “M” would be represented by a vector of 21 numbers (the scores of M with every other amino acid and X), and “A” would also be represented by its own 21-number vector.\nSequence Encoding: The encoded sequence becomes a matrix. If the original sequence was of length n, the encoded sequence is now an n x 21 matrix.\n\nThe train_data_iterator function is a generator that yields batches of training data. This function also handles filtering of alleles that might be present in the training data but not in the allele_sequences data to handle potential data inconsistencies.\ndef train_data_iterator(\n    df_train: pd.DataFrame,\n    train_allele_encoding: AlleleEncoding,\n    batch_size: int = 1024,\n) -&gt; Iterator[tuple[AlleleEncoding, EncodableSequences, np.ndarray]]:\n    \"\"\"\n    This function creates a data generator for training the neural network.\n    It iterates over the training data in batches and yields tuples of \n    (allele_encoding, peptide_sequences, labels).  It also handles filtering\n    of alleles not found in the initial allele encoding.\n    \"\"\"\n    # Get unique alleles in the training set.\n    alleles = df_train.allele.unique()\n    # Filter alleles to keep only those for which sequences are available.\n    usable_alleles = [\n        c for c in alleles if c in train_allele_encoding.allele_to_sequence\n    ]\n    print(\"Using %d / %d alleles\" % (len(usable_alleles), len(alleles)))\n    print(\n        \"Skipped alleles: \",\n        [c for c in alleles if c not in train_allele_encoding.allele_to_sequence],\n    )\n    df_train = df_train.query(\"allele in @usable_alleles\")\n\n    # Calculate the number of batches.\n    n_splits = np.ceil(len(df_train) / batch_size)\n\n    # Infinite loop to allow for multiple epochs.\n    while True:\n        # Split the training data into batches.\n        epoch_dfs = np.array_split(df_train.copy(), n_splits)\n        for k, df in enumerate(epoch_dfs):\n            if len(df) == 0:\n                continue\n            # Encode peptides and alleles for the current batch.\n            encodable_peptides = EncodableSequences(df.peptide.values)\n            allele_encoding = AlleleEncoding(\n                alleles=df.allele.values,\n                borrow_from=train_allele_encoding,  # Reuse encoding from main allele_encoding\n            )\n            # Yield the encoded data and labels (hit column).\n            yield (allele_encoding, encodable_peptides, df.hit.values)\nThe neural network model is initialized using the Class1BinaryNeuralNetwork class. Base hyperparameters are used for initialization. The model is then trained using the fit_generator method. This method takes the training data generator, validation data, and other parameters like the number of epochs and steps per epoch. The steps_per_epoch is calculated based on the training data size and batch size.\nmodel = Class1BinaryNeuralNetwork(**base_hyperparameters)\nsteps_per_epoch = np.ceil(len(df_train) / batch_size)\nbatch_size = 1024  # Define batch_size here\n\ntrain_generator = train_data_iterator(df_train, allele_encoding, batch_size) #create the generator\n\nmodel.fit_generator(\n    generator=train_generator,\n    validation_peptide_encoding=val_peptides,\n    validation_affinities=df_val.hit.values,\n    validation_allele_encoding=val_alleles,\n    validation_inequalities=None,\n    validation_output_indices=None,\n    steps_per_epoch=steps_per_epoch,\n    epochs=2,\n)\nThe Class1BinaryNeuralNetwork neural network takes two inputs:\n\nAllele: A single input representing the MHC allele.\nPeptide: A sequence of 45 amino acids represented as a 21-dimensional vector for each amino acid (likely using BLOSUM62 encoding or a similar technique).\n\nThe network then processes these inputs through several layers:\n\nEmbedding Layer: The allele input is passed through an embedding layer. This layer learns a 777-dimensional vector representation for each allele, capturing its key characteristics relevant to peptide binding.\nFlatten Layers: These layers reshape the input data. The peptide input, which is initially a 45x21 matrix, is flattened into a 945-element vector. Similarly, the 1x777 allele embedding is flattened into a 777-element vector. This prepares the data for the subsequent dense layers.\nConcatenate Layer: The flattened representations of the peptide and allele are combined into a single 1722-element vector. This crucial step merges the information from both inputs, allowing the network to learn the combined effect of allele and peptide on binding affinity.\nDense Layers: These are fully connected layers. The first dense layer transforms the 1722-element vector into a 1024-element vector, and the second further reduces it to 512 elements. These layers learn complex non-linear relationships between the combined allele and peptide representation, extracting features crucial for predicting binding affinity.\nDropout Layers: Dropout is a regularization technique. During training, these layers randomly “drop out” (ignore) a fraction of neurons. This prevents the network from overfitting to the training data and improves its ability to generalize to unseen data.\nOutput Layer: The final dense layer has a single output neuron. This neuron outputs a single value, representing the predicted binding affinity between the given peptide and MHC allele. Since we’re predicting a binary “hit” variable, a sigmoid activation function is used in this layer to output a probability between 0 and 1.\n\nThis architecture is designed to effectively learn the complex patterns governing MHC-peptide binding.\nFinally, the trained model is used to make predictions on the test data. The test data is preprocessed in the same way as the training data, and the predict method of the model is used to generate predictions. These predictions are then added to the test dataframe and saved to a CSV file.\ntest_peptides = df_test.peptide.values\ntest_allele_encoding = AlleleEncoding(\n    alleles=df_test.allele.values,\n    allele_to_sequence=allele_sequences_in_use.to_dict(),\n)\n\npredictions = model.predict(\n    peptides=test_peptides,\n    allele_encoding=test_allele_encoding,\n)\n\ndf_test[\"predictions\"] = predictions\ndf_test.to_csv(str(output_path / \"mhcpred_predictions.csv\"), index=False)\nWe evaluate the predictions of the two methods (mhcflurry and mhcpred) using standard binary classification metrics.\n\n\nMetrics\nThis notebook contains training metrics history and classification metrics computed on the predictions by - mhcflurry (benchmark) - mhcpred\n\nfrom pathlib import Path\nimport pickle\n\nfrom mhcpred.config import settings\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nmodels_path = Path(settings.models_path)\noutput_path = Path(settings.output_path)\n\nInformation on the training history\nI prefer to use tensorboard, but it is not implemented in the mhcflurry package. The information is quite scarce, but when you execute the code, you have the loss for each step and not only for the whole epoch. Of course, it is a very basic version of logging and should be improved.\n\nwith open(str(models_path / \"model.pickle\"), \"rb\") as f:\n    model = pickle.load(f)\n\n\nmodel.fit_info\n\n[{'learning_rate': 0.0010000000474974513,\n  'loss': [0.09700655937194824, 0.06465369462966919],\n  'val_loss': [0.06880103051662445, 0.05075661838054657],\n  'time': 524.7155420780182,\n  'num_points': 6628048}]\n\n\nBinary classification metrics\nWe compute the usual binary classification metrics on the unbalanced test dataset: accuracy, balanced accuracy, confusion matrix and classification report by scikit-learn.\nWe report the unbalanced accuracy because the dataset is very unbalanced so the accuracy only is not a good measure of accuracy (the model can predict always False and it works quite well).\nmhcflurry metrics\n\nmhcflurry_rank_percentile_threshold = 2  # rank threshold for positive hits\n# It comes from the mhcflurry article.\n\n\ndf = pd.read_csv(str(output_path / \"mhcflurry_predictions.csv\"))\ny_pred = df.prediction_percentile.values &lt;= mhcflurry_rank_percentile_threshold\ny_true = df.hit.values\nacc = accuracy_score(y_true=y_true, y_pred=y_pred)\nconfusion_mat = confusion_matrix(y_true=y_true, y_pred=y_pred)\nbalanced_acc = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\nclass_report = classification_report(y_true=y_true, y_pred=y_pred, output_dict=False)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_mat)\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nprint(class_report)\n\n              precision    recall  f1-score   support\n\n       False       0.99      0.98      0.99    900996\n        True       0.67      0.86      0.76     45423\n\n    accuracy                           0.97    946419\n   macro avg       0.83      0.92      0.87    946419\nweighted avg       0.98      0.97      0.97    946419\n\n\n\n\nacc, balanced_acc\n\n(0.9731936911663861, 0.9217833819652606)\n\n\nThe metrics are quite good. We note that we do not have a good precision on the True class (0.67), the model has a tendency to predict True too often, so we have too many False Positives. We see it on the confusion matrix, 19234 False Positives.\nmhcpred metrics\n\nmhcpred_proba_threshold = 0.5  # by default, but we try to tune it later\n\n\ndf = pd.read_csv(str(output_path / \"mhcpred_predictions.csv\"))\ny_true = df.hit.values\ny_pred = df.predictions.values &gt;= mhcpred_proba_threshold\nacc = accuracy_score(y_true=df.hit.values, y_pred=y_pred)\nconfusion_mat = confusion_matrix(y_true=df.hit.values, y_pred=y_pred)\nbalanced_acc = balanced_accuracy_score(y_true=df.hit.values, y_pred=y_pred)\n\nclass_report = classification_report(y_true=y_true, y_pred=y_pred, output_dict=False)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_mat)\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nacc, balanced_acc\n\n(0.9731657332258088, 0.7775326900487307)\n\n\n\nprint(class_report)\n\n              precision    recall  f1-score   support\n\n       False       0.98      0.99      0.99    900725\n        True       0.82      0.56      0.67     45416\n\n    accuracy                           0.97    946141\n   macro avg       0.90      0.78      0.83    946141\nweighted avg       0.97      0.97      0.97    946141\n\n\n\nmhcpred has worse performances compared to mhcflurry, see the balanced accuracy. On the True class, in that case, the recall is not good (0.56), the model has a tendency to predict False too often, on the confusion matrix we have 20000 True Negatives. It indicates that if we lower the threshold, we may improve the model.\nThreshold tuning\nWe plot the precision recall curve to try to identify a better threshold.\n\nfrom sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n\nprecision, recall, thresholds = precision_recall_curve(y_true=y_true, probas_pred=df.predictions.values)\ndisp = PrecisionRecallDisplay(precision=precision, recall=recall)\ndisp.plot()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nprecision_recall_thresholds = pd.DataFrame({\n    \"precision\": precision[:-1],\n    \"recall\": recall[:-1],\n    \"thresholds\": thresholds,\n})\n\n\nprecision_recall_thresholds\n\n\n\n\n\n\n\n\nprecision\nrecall\nthresholds\n\n\n\n\n0\n0.048001\n1.000000\n0.000114\n\n\n1\n0.048001\n1.000000\n0.000116\n\n\n2\n0.048001\n1.000000\n0.000117\n\n\n3\n0.048001\n1.000000\n0.000125\n\n\n4\n0.048002\n1.000000\n0.000125\n\n\n...\n...\n...\n...\n\n\n889313\n1.000000\n0.000110\n0.992152\n\n\n889314\n1.000000\n0.000088\n0.992280\n\n\n889315\n1.000000\n0.000066\n0.992347\n\n\n889316\n1.000000\n0.000044\n0.992431\n\n\n889317\n1.000000\n0.000022\n0.992971\n\n\n\n\n889318 rows × 3 columns\n\n\n\nA threshold of approx. 0.2 seems to be a good compromise for precision/recall.\n\nmhcpred_proba_threshold = 0.2\n\n\ndf = pd.read_csv(str(output_path / \"mhcpred_predictions.csv\"))\ny_true = df.hit.values\ny_pred = df.predictions.values &gt;= mhcpred_proba_threshold\nacc = accuracy_score(y_true=df.hit.values, y_pred=y_pred)\nconfusion_mat = confusion_matrix(y_true=df.hit.values, y_pred=y_pred)\nbalanced_acc = balanced_accuracy_score(y_true=df.hit.values, y_pred=y_pred)\n\nclass_report = classification_report(y_true=y_true, y_pred=y_pred, output_dict=False)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_mat)\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nacc, balanced_acc\n\n(0.9697360118629252, 0.8462451280426622)\n\n\n\nprint(class_report)\n\n              precision    recall  f1-score   support\n\n       False       0.99      0.98      0.98    900725\n        True       0.68      0.71      0.69     45416\n\n    accuracy                           0.97    946141\n   macro avg       0.83      0.85      0.84    946141\nweighted avg       0.97      0.97      0.97    946141\n\n\n\nWe see that we have improved the balanced accuracy. We have a deterioration of the precision but a better recall.\nSource: Metrics"
  },
  {
    "objectID": "posts/encoding-distances/unimol-gbf.html",
    "href": "posts/encoding-distances/unimol-gbf.html",
    "title": "Encoding Distances in Molecules and Pockets: A Comparison of GBFPT and DCEPT",
    "section": "",
    "text": "This blog post compares two different methods for encoding distances in 3D molecules and protein pockets: Gaussian kernel with pair type (GBFPT) and Discretization categorical embedding with Pair Type (DCEPT). We analyze their performance within the Uni-Mol framework, a universal 3D molecular representation learning model. We observed unstable gradients with GBFPT and hypothesized that DCEPT, inspired by AlphaFold’s distance representation, might offer a more stable alternative. We found that while DCEPT exhibits more stable training behavior, GBFPT ultimately yields superior pocket embeddings for retrieval tasks.\nBefore diving into the details, let’s define the acronyms used in this article:\n\nGBFPT: Gaussian Basis Function with Pair Type\nDCEPT: Discretization Categorical Embedding with Pair Type\n\n\nIntroduction to Uni-Mol and Distance Encoding\nCode for Uni-Mol is available at https://github.com/dptech-corp/Uni-Mol, and the related article is (Zhou et al. 2023). In brief, Uni-Mol is a 3D foundation model for molecules and pockets based on a SE(3) Transformer architecture. It comprises two pretrained models: one for molecular conformations and another for protein pocket data. Uni-Mol is pretrained on large-scale unlabeled data and is able to directly take 3D positions as both inputs and outputs. Uni-Mol backbone is a Transformer based model that can capture the input 3D information and predict 3D positions directly. Uni-Mol pretraining is done on two large-scale datasets: a 209M molecular conformation dataset and a 3M candidate protein pocket dataset, for pretraining 2 models on molecules and protein pockets, respectively. In the pretraining phase, Uni-Mol has to predict masked atoms, as well as masked noisy atoms coordinates and distances for effectively learning 3D spatial representation. The overall pretraining architecture is illustrated in Figure 2 and the framework is given in Figure 1 (taken from (Zhou et al. 2023)).\n\n\n\n\n\n\nFigure 1: Schematic illustration of the Uni-Mol framework\n\n\n\n\n\n\n\n\n\nFigure 2: Left: the overall pretraining architecture. Middle: the model inputs, including atom representation and pair representation. Right: details in the model block.\n\n\n\nBackground: 3D Spatial Encoding in Uni-Mol\nWe focus here on the encoding of the coordinates in distances (pair representation in Figure 2 middle part) and the decoding part, prediction of distances (pair-dist head in Figure 2 left part). In (Zhou et al. 2023) Section D.1, 3D spatial positional encodings benchmark, they investigate the performance of different 3D spatial positional encoding on the 3D molecular pretraining. In particular, they benchmarked:\n\nGaussian kernel (GK), a simply Gaussian density function.\nGaussian kernel with pair type (GKPT) (Shuaibi et al. 2021). Based on GK, an affine transformation according to the pair type is applied on pair distances, before applying the Gaussian kernel.\nRadial Bessel basis (RBB) (Gasteiger, Yeshwanth, and Günnemann 2021). A Bessel based radial function.\nDiscretization categorical embedding (DCE). They convert the continued distances to the discrete bins, by Discretization. With binned distances, embedding-based positional encoding is directly used.\nDelta coordinate (DC) (Zhao et al. 2021). Following Point Transformer, the deltas of coordinates are directly used as pair-wise spatial relative positional encoding.\nGaussian kernel with pair type and local graph (GKPTLG). Based on GKPT, they set up a model with locally connected graphs. In particular, the cutoff radius is set to 6 Å.\n\nThe validation loss during pretraining for each encoding is summarized in Figure 3 (taken from (Zhou et al. 2023)). From the results, they drew the following conclusions:\n\nThe performance of DCE and GK are almost the same, and outperform RBB and DC. And they choose GK as the basic encoding.\nCompared with GK, GKPT converges faster. This indicates the pair type is critical in the 3D spatial positional encoding.\nCompared with GKPT, GKPTLG converges slower. This indicates the locally cutoff graph is not effective for self-supervised learning, and the default fully connected graph structure inherent in the Transformer architecture is more effective.\nAs GKPT outperforms all other encoding, they use it in the backbone model of Uni-Mol.\n\n\n\n\n\n\n\nFigure 3: Validation loss in pretraining for different 3D spatial encodings\n\n\n\nThe code for the GKPT encoding is given by:\nimport torch\nimport torch.nn as nn\n\n@torch.jit.script\ndef gaussian(x, mean, std):\n    pi = 3.14159\n    a = (2 * pi) ** 0.5\n    return torch.exp(-0.5 * (((x - mean) / std) ** 2)) / (a * std)\n\n\nclass GaussianLayer(nn.Module):\n    def __init__(self, K=128, edge_types=1024):\n        super().__init__()\n        self.K = K\n        self.means = nn.Embedding(1, K)\n        self.stds = nn.Embedding(1, K)\n        self.mul = nn.Embedding(edge_types, 1)\n        self.bias = nn.Embedding(edge_types, 1)\n        nn.init.uniform_(self.means.weight, 0, 3)\n        nn.init.uniform_(self.stds.weight, 0, 3)\n        nn.init.constant_(self.bias.weight, 0)\n        nn.init.constant_(self.mul.weight, 1)\n\n    def forward(self, x, edge_type):\n        mul = self.mul(edge_type).type_as(x)\n        bias = self.bias(edge_type).type_as(x)\n        x = mul * x.unsqueeze(-1) + bias\n        x = x.expand(-1, -1, -1, self.K)\n        mean = self.means.weight.float().view(-1)\n        std = self.stds.weight.float().view(-1).abs() + 1e-5\n        return gaussian(x.float(), mean, std).type_as(self.means.weight)\nK represents the number of Gaussian basis functions, edge_types the number of possible edge types, x the distance matrix (for an initial 3D molecule or pocket) and edge_type the corresponding edge type matrix. Edge types represent the different types of atom pairs (e.g., C-C, C-O, C-N, etc.)\n\n\nExperimental Setup\n\n\n\n\n\n\nNote\n\n\n\nAll the Uni-Mol experiments run for this article are based on a small pockets dataset inspired from the PDBbind database (http://www.pdbbind.org.cn/), a collection of protein-ligand complexes and their binding affinities. The dataset was split into training and validation sets based on pocket similarity. The wandb project is available https://wandb.ai/nicolasb/unimol_analysis/ as well as a summary report https://api.wandb.ai/links/nicolasb/kdz59bry.\n\n\nMotivation for DCEPT and Implementation\nWhen we train Uni-Mol on a small dataset of pockets inspired from the PDBbind database, we remark that the gradients related to GaussianLayer parameters are not stable and can take very large values. To address the gradient instability observed with GBFPT, and drawing inspiration from AlphaFold’s use of discretization, we explored using a Discretization Categorical Embedding with Pair Type (DCEPT) as an alternative. In Figure 4, some gradients are of the order of one thousand. Uni-Mol relies on Uni-Core which implements gradient clipping and these high values do not affect the stability of the training.\n\n\n\n\n\n\nFigure 4: Gradients of GaussianLayer parameters (GBFPT encoding)\n\n\n\nNevertheless, we wanted to try another encoding that would be naturally stable without exploding gradients. Furthermore, DCE is the encoding used in AlphaFold (Jumper et al. 2021). We implemented Discretization categorical embedding with Pair Type encoding (DCEPT) that takes into account the edge type. A distogram is a discrete representation of the distance matrix, where distances are binned into predefined intervals. The binning process transforms continuous distances into discrete categories.\nimport torch\nimport torch.nn as nn\n\n# Constants\nPAD_DIST = 0\n\nclass NonLinearModule(nn.Module):\n    def __init__(self, input_dim, out_dim, activation_fn):\n        super().__init__()\n        self.linear = nn.Linear(input_dim, out_dim)\n        self.activation = getattr(nn, activation_fn)()\n\n    def forward(self, x):\n        return self.activation(self.linear(x))\n\nclass DistEncoding(nn.Module):\n    def __init__(\n        self,\n        distogram_nb_bins: int,\n        nb_edge_types: int,\n        embedding_dim: int,\n        edge_type_padding_idx: int,\n        encoder_attention_heads: int,\n        activation_fn: str,\n    ):\n        \"\"\"\n        Initializes the DistEncoding module for encoding distances and edge types.\n\n        Args:\n            distogram_nb_bins: Number of bins for the distogram (distance discretization).\n            nb_edge_types: Number of possible edge types (e.g., different bond types).\n            embedding_dim: Dimension of the embeddings for distances and edge types.\n            edge_type_padding_idx: Padding index for edge type embeddings.\n            encoder_attention_heads: Number of attention heads in the Transformer encoder.\n            activation_fn: Activation function to use in the projection layer.\n        \"\"\"\n        super(DistEncoding, self).__init__()\n\n        # Embedding layer for the distogram (discretized distances)\n        self.dist_embedding = nn.Embedding(\n            num_embeddings=distogram_nb_bins,\n            embedding_dim=embedding_dim,\n            padding_idx=PAD_DIST,  # Use PAD_DIST for padding\n        )\n\n        # Embedding layer for edge types\n        self.edge_type_embedding = nn.Embedding(\n            num_embeddings=nb_edge_types,\n            embedding_dim=embedding_dim,\n            padding_idx=edge_type_padding_idx,\n        )\n\n        # Projection layer to combine distance and edge type embeddings and project\n        # to the correct dimension for attention bias.\n        self.projection = NonLinearModule(\n            input_dim=2 * embedding_dim,  # Concatenate dist and edge embeddings\n            out_dim=encoder_attention_heads,  # Output dimension matches attention heads\n            activation_fn=activation_fn,\n        )\n\n    def forward(\n        self, distogram: torch.Tensor, edge_types: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the DistEncoding module.\n\n        Args:\n            distogram: Tensor of discretized distances (batch_size, seq_len, seq_len).\n            edge_types: Tensor of edge types (batch_size, seq_len, seq_len).\n\n        Returns:\n            attn_bias: Tensor of attention biases (batch_size, num_heads, seq_len, seq_len).\n        \"\"\"\n        n_node = distogram.size(-1)  # Sequence length (number of nodes/atoms)\n\n        # Embed the discretized distances\n        dist_embeddings = self.dist_embedding(distogram)  # (B, L, L, D)\n\n        # Embed the edge types\n        edge_types_embeddings = self.edge_type_embedding(edge_types)  # (B, L, L, D)\n\n        # Concatenate distance and edge type embeddings\n        embeddings = torch.cat((dist_embeddings, edge_types_embeddings), dim=-1)  # (B, L, L, 2D)\n\n        # Project the combined embeddings to generate attention bias\n        attn_bias = self.projection(embeddings)  # (B, L, L, H) where H = num_heads\n\n        # Reshape the attention bias to the correct format for the Transformer\n        attn_bias = attn_bias.permute(0, 3, 1, 2).contiguous()  # (B, H, L, L)\n        attn_bias = attn_bias.view(-1, n_node, n_node) # (B*H, L, L) - Correct if attention is applied per head.\n        return attn_bias\ndistogram_nb_bins is the number of bins (128 by default), nb_edge_types the number of edge types, embedding_dim the dimension of the embedding (128 by default), encoder_attention_heads the number of attention heads in the transformer because the distance encoding is directly injected in the attention matrix. distogram is the distogram (discretization of the distance matrix) and edge_types the edge types. We concatenate the two embeddings creating de facto the DCEPT and then project to feed into the attention matrix.\nTraining Dynamics\nDuring the training, the gradients related to DistEncoding parameters do not take large values and are naturally stable without clipping gradients. This is illustrated in Figure 5.\n\n\n\n\n\n\nFigure 5: Gradients of DistEncoding parameters (DCEPT encoding)\n\n\n\nFollowing (Jumper et al. 2021) distogram prediction task, we also replace the distance prediction task (mean squared error loss) implemented in Uni-Mol by a distogram prediction task (cross entropy loss). We remark that this loss replacement does not change the characteristics of Uni-Mol.\nOn the small pockets inspired from the PDBbind database, we notice that the training and validation loss curves are better with DCEPT encoding compared to GBFPT encoding (on average), see Figure 6. More precisely, the masked_token_loss and the masked_acc metrics related to the recovery of masked atoms seem to stagnate a little at first with DCEPT encoding compared to GBFPT encoding. It may be due to the fact that DCEPT are at first completely random embeddings and less intuitive for the neural network. However, the masked_coord_loss is better with DCEPT encoding both in the training and validation sets. Note that the masked_distogram_loss corresponds to the distogram loss (cross entropy loss) used in AlphaFold (Jumper et al. 2021) and is implemented only for DCEPT encoding. For DCEPT encoding, we also add a distance prediction head with the corresponding MSE loss taken from Uni-Mol and a small multiplication factor (0.01). The rationale for including this head was to maintain some of the original Uni-Mol distance prediction capabilities alongside the distogram prediction. That explains why the DCEPT masked_dist_loss decreases slightly slower than GBFPT. Several additional experiments (not shown here) demonstrate that using a distogram or distance loss does not change the behavior of Uni-Mol.\nIn conclusion, according to the loss curves and the stability of the gradients, DCEPT seems to be a better encoding than GBFPT (or at least as good as) during pre-training.\n\n\n\n\n\n\nFigure 6: Uni-Mol training and validation losses with GBFPT and DCEPT encoding\n\n\n\n\n\nDownstream Performance: Pocket Retrieval\nHowever, Uni-Mol stands as a foundational model pre-trained through unsupervised methods. The pre-training metrics do not reflect the expected capabilities of the model. Notably, we expect that the pockets embeddings obtained with Uni-Mol should be good proxies of the pockets themselves: if two pockets are close to each other, their embeddings should be close in cos similarity or euclidean distance.\nWe have collected a dataset of 5 pockets (taken from 2oax, 3oxc, 5kxi, 5zk3 and 6v7a proteins) and for each pocket, a group of similar and dissimilar pockets. We compute the cos similarities between each reference pocket and the similar/dissimilar pockets and we sort the pockets by their cos similarity. Better embeddings translate into more similar pockets in the top retrieved pockets. More precisely, we sort the pockets by their cos similarities, we select the top 100 pockets, we count the number of similar pockets in the top 100 and we get a number between 0 and 1, the higher the better. We test two different embeddings: either, the vector corresponding to the [CLS] token (see (Zhou et al. 2023) Section 2.2) (indicated by _cls) or the mean of the pocket atoms vectors (indicated by _mean). Table 1 summarizes the results for each encoding, embedding and reference pocket and we remark that\n\nGBFPT is superior to DCEPT for pockets retrieval,\nThe mean of the pocket atoms vectors is better or near as good as the [CLS] embedding.\n\n\n\n\nTable 1: Uni-Mol pockets retrieval with GBFPT or DCEPT encoding (higher is better)\n\n\n\n\n\n\n6v7a\n2oax\n5kxi\n5zk3\n3oxc\n\n\n\n\nunimol_gbfpt_cls\n0.46\n1.0\n0.32\n0.3\n1.0\n\n\nunimol_gbfpt_mean\n0.79\n1.0\n0.38\n0.29\n1.0\n\n\nunimol_dcept_cls\n0.3\n1.0\n0.26\n0.29\n1.0\n\n\nunimol_dcept_mean\n0.51\n1.0\n0.27\n0.28\n1.0\n\n\n\n\n\n\nInvestigating Noise Sensitivity\nIn conclusion, despite better pre-training behavior and metrics, DCEPT encoding is disappointing when it comes to embeddings comparison. We suppose that this defect comes from a higher sensitivity of the discretization procedure. Two distance matrices from two close pockets may be more distinctly differentiated with DCEPT encoding compared to GBFPT encoding. This could be due to the information loss inherent in discretizing continuous distances. GBFPT might be capturing subtle long-range interactions that DCEPT, with its discrete representation, misses. To test this hypothesis, we take the 6v7a pocket and we noise its coordinates with a uniform noise between 0 and 1A. Since we have a batch size of 16, we fill up a batch with the reference pocket 6v7a and 15 noisy pockets. For each pocket, the distance matrix is encoded by GBFPT or DCEPT and we get an encoding of size 128 for each distance in the distance matrix. We compute the cos similarities between each encoding and the reference encoding in the reference matrix distance of 6v7a and we obtain the overall statistics of these cos similarities for GBFPT and DCEPT. In Table 2, we have the absolute errors statistics between 1 and the cos similarities of the noisy pockets from 6v7a, the lower the better because the vectors are similar. We remark that as presumed DCEPT encoding is less robust to noise compared to GBFPT encoding.\n\n\n\nTable 2: Statistics of cos similarities errors for noisy pockets from 6v7a\n\n\n\n\n\n\n\n\n\n\n\nAbsolute errors cos similarities GBFPT encoding (1 - cos similarities)\nAbsolute errors cos similarities DCEPT encoding (1 - cos similarities)\n\n\n\n\nmean\n0.002\n0.020\n\n\nmedian\n0.000\n0.007\n\n\n\n\n\n\n\n\nConclusion\nThese results suggest that while DCEPT offers advantages during pre-training in terms of gradient stability, the discretization process might lead to a loss of information and reduced robustness, ultimately hindering the quality of the generated pocket embeddings for downstream tasks like pocket retrieval. Further research is needed to investigate the optimal bin size for distograms and to explore alternative distance encoding techniques that balance stability and information retention. This analysis was conducted on a small, custom-built pocket dataset, and future work should evaluate these encoding methods on larger, more diverse datasets to ensure the generalizability of our findings.\n\n\n\n\n\nReferences\n\nGasteiger, Johannes, Chandan Yeshwanth, and Stephan Günnemann. 2021. “Directional Message Passing on Molecular Graphs via Synthetic Coordinates.” In Advances in Neural Information Processing Systems, edited by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. Wortman Vaughan, 34:15421–33. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2021/file/82489c9737cc245530c7a6ebef3753ec-Paper.pdf.\n\n\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. “Highly Accurate Protein Structure Prediction with AlphaFold.” Nature 596 (7873): 583–89. https://doi.org/10.1038/s41586-021-03819-2.\n\n\nShuaibi, Muhammed, Adeesh Kolluru, Abhishek Das, Aditya Grover, Anuroop Sriram, Zachary Ulissi, and C. Lawrence Zitnick. 2021. “Rotation Invariant Graph Neural Networks Using Spin Convolutions.” https://arxiv.org/abs/2106.09575.\n\n\nZhao, Hengshuang, Li Jiang, Jiaya Jia, Philip Torr, and Vladlen Koltun. 2021. “Point Transformer.” In 2021 IEEE/CVF International Conference on Computer Vision (ICCV), 16239–48. https://doi.org/10.1109/ICCV48922.2021.01595.\n\n\nZhou, Gengmo, Zhifeng Gao, Qiankun Ding, Hang Zheng, Hongteng Xu, Zhewei Wei, Linfeng Zhang, and Guolin Ke. 2023. “Uni-Mol: A Universal 3D Molecular Representation Learning Framework.” In The Eleventh International Conference on Learning Representations. https://openreview.net/forum?id=6K2RM6wVqKu."
  }
]